---
title: '"Acceptabiliy Analysis for Catalan and Spanish Ratings"'
author: "ASSASSMG"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r, setup, include=FALSE}
# The following line sets the [working directory](https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html) for reading in the files. 
# Exchange the part before `/CaSpaSyn/code` with wherever you have the copy of the repository.
knitr::opts_knit$set(root.dir = "~/repos/CaSpaSyn/code/")

# Don't include warnings and messages in the rendered document.
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r packages, include=FALSE}
# Load/install libraries. 
#install.packages("tidyverse")
packages <- c("tidyverse", "lubridate", "gridExtra", "car", "namer", "dplyr", "magrittr", "ggplot2", "ggthemes")

installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
	install.packages(packages[!installed_packages])
}

invisible(lapply(packages, library, character.only = TRUE))
```

# Data Exploration

```{r loadData}
# Load data.
df.cat.initial <- read_csv("../data/Catalan_ASSASSMG.csv")
df.spa.initial <- read_csv("../data/Spanish_ASSASSMG.csv")

# Print data overview.
str(df.cat.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
str(df.spa.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
```

Make sure that the ratings are treated as numerical data, not strings. 
```{r dataTreatment, include = FALSE}
df.cat <- transform(df.cat.initial, Rating = as.numeric(Rating))
df.spa <- transform(df.spa.initial, Rating = as.numeric(Rating))
```

## Overall Rating Distribution

Ratings are very skewed towards the high end of the scale.

```{r ratingBoxplot}
box.spa <- ggplot(df.spa, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="antiquewhite4", fill="bisque4"
                   ) + 
    scale_x_continuous(n.breaks=7) +
    scale_y_continuous(limits = c(0, 500)) +
    labs(y = "Rating count", x = "Rating scale point") + 
    theme_hc() +
    scale_fill_hc() + 
    ggtitle("Spanish Ratings")

box.cat <- ggplot(df.cat, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="antiquewhite4", fill="bisque4"
                   ) + 
    labs(y = "Rating count", x = "Rating scale point") + 
    theme_hc() +
    scale_fill_hc() + 
    scale_x_continuous(n.breaks=7) + 
    scale_y_continuous(limits = c(0, 500)) +
    ggtitle("Catalan Ratings")

grid.arrange(box.spa, box.cat, ncol=2)
ggsave(filename = "/mnt/c/Users/astei/Desktop/rating_count_distribution.png")
```

Beide DatensÃ¤tze sind nicht normalverteilt:

```{r normalityAllRatings, echo=FALSE}
shapiro.test(df.cat$Rating)
shapiro.test(df.spa$Rating)
```

## Outlier Inspection

### Participants

Subset data by participants

```{r}
participants.spa <- df.spa %>%
    select(Code, Rating) %>%
    group_by(Code)

participants.cat <- df.cat %>%
    select(Code, Rating) %>%
    group_by(Code)
```

Plots of rating distribution per participant.

Catalan participants:

```{r}
ggplot(data = participants.cat, aes(Rating)) +
  geom_histogram(binwidth=.5, na.rm = TRUE, fill="bisque4", color="antiquewhite4") +
  labs(title = "Rating distribution per participant - Catalan",
  y = "Rating count", x = "Rating scale point") + 
  scale_x_continuous("Rating", labels = as.character(participants.cat$Rating), breaks = participants.cat$Rating) +
  theme_hc() +
  scale_fill_hc() + 
  facet_wrap(~ Code)
ggsave("../figures/ratingDistributionCatalan.png")
```

Castillian participants:

```{r}
ggplot(data = participants.spa, aes(Rating)) +
  geom_histogram(binwidth=.5, na.rm = TRUE, fill="bisque4", color="antiquewhite4")+
  labs(title = "Rating distribution per participant - Spanish",
  y = "Rating count", x = "Rating scale point") + 
  scale_x_continuous("Rating", labels = as.character(participants.spa$Rating), breaks = participants.spa$Rating) +
    theme_hc() +
  scale_fill_hc() + 
  facet_wrap(~ Code)
#ggsave("../figures/ratingDistributionCastillian.png")
```

### Survey Completion Time

Check for completion times 1 standard deviation away from average survey
completion time
([source](https://academic.oup.com/poq/article/72/5/914/1832496#28138951)).

Calculate survey duration.

```{r surveytime, results = "hide", echo = FALSE}
df.cat <- df.cat %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))
df.spa <- df.spa %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))

participants.cat$surveyduration <- df.cat$surveyduration
participants.spa$surveyduration <- df.spa$surveyduration

participants.cat.unique <- participants.cat %>% 
  distinct(Code, .keep_all = T)

participants.spa.unique <- participants.spa %>% 
  distinct(Code, .keep_all = T)
```

Plot survey durations per participant. 

```{r}
dur.spa <- ggplot(participants.spa.unique)  + 
  geom_bar( aes(x=reorder(Code,surveyduration,na.rm = TRUE), y=surveyduration), stat = "identity",  fill="bisque4", color="antiquewhite4") + 
  theme(axis.text.x = element_text(angle = 90)) +
  theme_hc() +
  scale_fill_hc() + 
  labs(title = "Survey duration per participant - Spanish",
  y = "Survey duration in seconds", x = "Code")
#ggsave("../figures/surveydurParticipantsCastillian.png")


dur.cat <- ggplot(unique(participants.cat.unique), aes(x=reorder(Code,surveyduration,na.rm = TRUE), y=surveyduration)) + 
  geom_bar(stat = "identity",  fill="bisque4", color="antiquewhite4") + 
  theme(axis.text.x = element_text(angle = 90)) +
  theme_hc() +
  scale_fill_hc() + 
  labs(title = "Survey duration per participant - Catalan",
  y = "Survey duration in seconds", x = "Code")

dur.spa
#ggsave("../figures/surveydurParticipantsCatalan.png")
```


```{r}
mean(df.cat$surveyduration) + 1.5 * sd(df.cat$surveyduration) 
mean(df.cat$surveyduration) + 1 * sd(df.cat$surveyduration) 
mean(df.spa$surveyduration) - 1.5 * sd(df.spa$surveyduration)  
mean(df.spa$surveyduration) - 1 * sd(df.spa$surveyduration)  
```
```{r}
mean(df.spa$surveyduration) + 1.5 *sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) + 1 * sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) - 1.5 * sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) - 1 * sd(df.spa$surveyduration) 
```

```{r exclusionTimes}
nrow(subjTimes.cat %>% filter(surveyduration < 10 | surveyduration > 17)) # 7/25
nrow(subjTimes.cat %>% filter(surveyduration < 8 | surveyduration > 19)) # 2/25

nrow(subjTimes.spa %>% filter(surveyduration < 8 | surveyduration > 19)) # 10/25 
nrow(subjTimes.spa %>% filter(surveyduration < 6 | surveyduration > 21)) # 3/26
```


# Animacy Comparison 1.5 SD

For the category "all verbs", as well as each individual verb (encantar, divertir, molestar, espantar,...), you will find the following code-blocks:

1. Create relevant subsets for Shapiro Test to test for normal distribution
2. Shapiro Tests for subsets created in 1.
3. New subsets to compare the relevant animacy properties; Shapiro Tests conducted with those subsets (not sure if that was necessary, but bettr safe than sorry), Levene Test
4. Mann-Whitney U Test & means output via tapply
5. First comments

A note on the Levene Test: 
Depending on whether the median or the mean is used as center, the resulting numbers differ by quite a lot.
As far as I understood, the median version is more robust against not normally distributed Data.


**ALL VERBS**

```{r}

#Subset with 1.5 SD taken into account
df.cat.SD <-  subset(df.cat, surveyduration > 8 & surveyduration < 18) 

#Create relevant subsets to test for animacy effects throughout all verbs
df.cat.allAA <- subset(df.cat.SD, Sentencetype == "AA")
df.cat.allAI <- subset(df.cat.SD, Sentencetype == "AI")
df.cat.allPA <- subset(df.cat.SD, Sentencetype == "PA")
df.cat.allPI <- subset(df.cat.SD, Sentencetype == "PI")
df.cat.allPN <- subset(df.cat.SD, Sentencetype == "PN")

```

```{r}

#Shapiro Test to test for normal distribution (anything below 0.05 is not normal)
shapiro.test(df.cat$Rating)  # <2.2e-16 (not normal distribution)

#Shapiro test to test for normal distribution among the Sentencytype subsets

shapiro.test(df.cat.allAA$Rating) # = 3.669e-11 
shapiro.test(df.cat.allAI$Rating) # = 9.129e-15
shapiro.test(df.cat.allPA$Rating) # = 1.234e-12
shapiro.test(df.cat.allPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPN$Rating) # = 3.493e-15

```

```{r}

#Levene test

library(car) #necessary for levene test to work

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.allAAAI <- subset(df.cat.SD, Sentencetype %in% c('AA','AI'))
df.cat.allPAPI <- subset(df.cat.SD, Sentencetype %in% c('PA','PI'))
df.cat.allAAPA <- subset(df.cat.SD, Sentencetype %in% c('AA','PA'))
df.cat.allAIPI <- subset(df.cat.SD, Sentencetype %in% c('AI','PI'))
df.cat.allPAPN <- subset(df.cat.SD, Sentencetype %in% c('PA','PN'))
df.cat.allPIPN <- subset(df.cat.SD, Sentencetype %in% c('PI','PN'))



#shapiro tests for new subsets, just in case (unsurprisingly, none are normally distributed)

shapiro.test(df.cat.allAAAI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allAAPA$Rating) # < 2.2e-16
shapiro.test(df.cat.allAIPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPN$Rating) # < 2.2e-16
shapiro.test(df.cat.allPIPN$Rating) # < 2.2e-16



#Levene Test to test for variance among all verbs
#"*" mark how significant the variance is
#The more "*", the more significant

#All verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI) # 0.4718
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI, center=mean) # 0.6694


#All verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI) # 0.005916 **
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI, center=mean) # 0.001856 **


#All verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA) # 0.5944
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA, center=mean) # 0.4298


#All verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI) # 0.07434 .
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI, center=mean) # 0.0449 *


#All verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN) # 0.03396 *
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN, center=mean) # 0.008109 **


#All verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN) # 0.5523
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN, center=mean) # 0.5401

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

tapply(df.cat.SD$Rating, list(df.cat.SD$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#All verbs AA & AI
wilcox.test(df.cat.allAAAI$Rating ~ df.cat.allAAAI$Sentencetype) # = 0.1395



#All verbs PA &PI
wilcox.test(df.cat.allPAPI$Rating ~ df.cat.allPAPI$Sentencetype) # = 0.0005472


#All verbs AA & PA
wilcox.test(df.cat.allAAPA$Rating ~ df.cat.allAAPA$Sentencetype) # = 0.9857


#All verbs AI & PI
wilcox.test(df.cat.allAIPI$Rating ~ df.cat.allAIPI$Sentencetype) # = 0.03014


#All verbs PA & PN
wilcox.test(df.cat.allPAPN$Rating ~ df.cat.allPAPN$Sentencetype) # = 0.005223 


#All verbs PI & PN
wilcox.test(df.cat.allPIPN$Rating ~ df.cat.allPIPN$Sentencetype) # = 0.4744 

```


Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AA&PA, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AI&PI 
  - The means differ significantly in the following pairs:                PA&PI, AI&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AA&PA, PI&PN
  



# PER VERB

#encantar (C)
#divertir (D)
#espanatr (E)
#molestar (M)
#preocupar (P)
#sorprendre (S)
#entristir (T)
#estranyar (U)


ENCANTAR
```{r}
#Create relevant subsets to test for animacy effects throughout ENCANTAR (C)
df.cat.encantarAA <- subset(df.cat.allAA, Verb == "C")
df.cat.encantarAI <- subset(df.cat.allAI, Verb == "C")
df.cat.encantarPA <- subset(df.cat.allPA, Verb == "C")
df.cat.encantarPI <- subset(df.cat.allPI, Verb == "C")
df.cat.encantarPN <- subset(df.cat.allPN, Verb == "C")

```

```{r}
#Shapiro test to test for normal distribution among the ENCANTAR (C) subsets
shapiro.test(df.cat.encantarAA$Rating) # = 0.004527
shapiro.test(df.cat.encantarAI$Rating) # = 0.05218
shapiro.test(df.cat.encantarPA$Rating) # = 0.04389
shapiro.test(df.cat.encantarPI$Rating) # = 0.008644
shapiro.test(df.cat.encantarPN$Rating) # = 0.0278


```
 
```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.encantarAAAI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AA','AI'))
df.cat.encantarPAPI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PA','PI'))
df.cat.encantarAAPA <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AA','PA'))
df.cat.encantarAIPI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AI','PI'))
df.cat.encantarPAPN <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PA','PN'))
df.cat.encantarPIPN <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.encantarAAAI$Rating) # = 0.0003561
shapiro.test(df.cat.encantarPAPI$Rating) # = 0.0005639
shapiro.test(df.cat.encantarAAPA$Rating) # = 0.0005873
shapiro.test(df.cat.encantarAIPI$Rating) # = 0.001555
shapiro.test(df.cat.encantarPAPN$Rating) # = 0.001841
shapiro.test(df.cat.encantarPIPN$Rating) # = 0.0007828


#Levene Test to test for variance among all verbs
#ENCANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI) # 0.2156
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI, center=mean) # 0.1227


#ENCANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI) # 1?
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI, center=mean) # 0.8444


#ENCANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA) # 0.5301
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA, center=mean) # 0.3724


#ENCANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI) # 0.5039
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI, center=mean) # 0.5554


#ENCANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN) # 0.9078
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN, center=mean) # 0.7327


#ENCANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN) # 0.9072
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN, center=mean) # 0.6091



```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.encantar <- subset(df.cat.SD, Verb == "C")
tapply(df.cat.encantar$Rating, list(df.cat.encantar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ENCANTAR AA & AI
wilcox.test(df.cat.encantarAAAI$Rating ~ df.cat.encantarAAAI$Sentencetype) # = 1


#ENCANTAR PA &PI
wilcox.test(df.cat.encantarPAPI$Rating ~ df.cat.encantarPAPI$Sentencetype) # = 0.3336


#ENCANTAR AA & PA
wilcox.test(df.cat.encantarAAPA$Rating ~ df.cat.encantarAAPA$Sentencetype) # = 0.165


#ENCANTAR AI & PI
wilcox.test(df.cat.encantarAIPI$Rating ~ df.cat.encantarAIPI$Sentencetype) # = 0.01126



#ENCANTAR PA & PN
wilcox.test(df.cat.encantarPAPN$Rating ~ df.cat.encantarPAPN$Sentencetype) # = 0.4567


#ENCANTAR PI & PN
wilcox.test(df.cat.encantarPIPN$Rating ~ df.cat.encantarPIPN$Sentencetype) # = 0.09088

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI AA&PA, AI&PI, PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AI&PI
  - The means do NOT differ significantly in the following pairs:         AA&AI, PA&PI, AA&PA, PA&PN, PI&PN




DIVERTIR

```{r}

#Create relevant subsets to test for animacy effects throughout DIVERTIR (D)
df.cat.divertirAA <- subset(df.cat.allAA, Verb == "D")
df.cat.divertirAI <- subset(df.cat.allAI, Verb == "D")
df.cat.divertirPA <- subset(df.cat.allPA, Verb == "D")
df.cat.divertirPI <- subset(df.cat.allPI, Verb == "D")
df.cat.divertirPN <- subset(df.cat.allPN, Verb == "D")

```

```{r}
#Shapiro test to test for normal distribution among the DIVERTIR (D) subsets
shapiro.test(df.cat.divertirAA$Rating) # = 0.004375
shapiro.test(df.cat.divertirAI$Rating) # = 5.072e-06
shapiro.test(df.cat.divertirPA$Rating) # = 0.0003258
shapiro.test(df.cat.divertirPI$Rating) # = 7.704e-05
shapiro.test(df.cat.divertirPN$Rating) # = 0.001077

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.divertirAAAI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AA','AI'))
df.cat.divertirPAPI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PA','PI'))
df.cat.divertirAAPA <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AA','PA'))
df.cat.divertirAIPI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AI','PI'))
df.cat.divertirPAPN <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PA','PN'))
df.cat.divertirPIPN <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.divertirAAAI$Rating) # = 8.95e-07
shapiro.test(df.cat.divertirPAPI$Rating) # = 4.164e-07
shapiro.test(df.cat.divertirAAPA$Rating) # = 2.876e-05
shapiro.test(df.cat.divertirAIPI$Rating) # = 4.122e-08
shapiro.test(df.cat.divertirPAPN$Rating) # = 2.85e-06
shapiro.test(df.cat.divertirPIPN$Rating) # = 3.401e-06


#Levene Test to test for variance among all verbs
#DIVERTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI) # 0.002058 **
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI, center=mean) # 0.001191 **


#DIVERTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI) # 0.1531
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI, center=mean) # 0.04549 *


#DIVERTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA) # 0.8207
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA, center=mean) # 0.9024


#DIVERTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI) # 0.4418
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI, center=mean) # 0.5447


#DIVERTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN) # 0.1387
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN, center=mean) # 0.03015 *


#DIVERTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN) # 0.759
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN, center=mean) # 0.8945

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.divertir <- subset(df.cat.SD, Verb == "D")
tapply(df.cat.divertir$Rating, list(df.cat.divertir$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#DIVERTIR AA & AI
wilcox.test(df.cat.divertirAAAI$Rating ~ df.cat.divertirAAAI$Sentencetype) # = 0.01265


#DIVERTIR PA &PI
wilcox.test(df.cat.divertirPAPI$Rating ~ df.cat.divertirPAPI$Sentencetype) # = 0.3781


#DIVERTIR AA & PA
wilcox.test(df.cat.divertirAAPA$Rating ~ df.cat.divertirAAPA$Sentencetype) # = 0.4372


#DIVERTIR AI & PI
wilcox.test(df.cat.divertirAIPI$Rating ~ df.cat.divertirAIPI$Sentencetype) # = 0.3817


#DIVERTIR PA & PN
wilcox.test(df.cat.divertirPAPN$Rating ~ df.cat.divertirPAPN$Sentencetype) # = 0.7729 


#DIVERTIR PI & PN
wilcox.test(df.cat.divertirPIPN$Rating ~ df.cat.divertirPIPN$Sentencetype) # = 0.4485

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI
  - The variance does NOT differ significantly in the following pairs:    AA&PA, AI&PI, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PI, PA&PN
  - The means differ significantly in the following pairs:                AA&AI
  - The means do NOT differ significantly in the following pairs:         PA&PI, AA&PA, AI&PI, PA&PN, PI&PN



ESPANTAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESPANTAR (E)
df.cat.espantarAA <- subset(df.cat.allAA, Verb == "E")
df.cat.espantarAI <- subset(df.cat.allAI, Verb == "E")
df.cat.espantarPA <- subset(df.cat.allPA, Verb == "E")
df.cat.espantarPI <- subset(df.cat.allPI, Verb == "E")
df.cat.espantarPN <- subset(df.cat.allPN, Verb == "E")

```

```{r}
#Shapiro test to test for normal distribution among the ESPANTAR (E) subsets
shapiro.test(df.cat.espantarAA$Rating) # = 0.02895
shapiro.test(df.cat.espantarAI$Rating) # = 0.0004889
shapiro.test(df.cat.espantarPA$Rating) # = 0.02107
shapiro.test(df.cat.espantarPI$Rating) # = 3.892e-05
shapiro.test(df.cat.espantarPN$Rating) # = 1.689e-05

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.espantarAAAI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AA','AI'))
df.cat.espantarPAPI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PA','PI'))
df.cat.espantarAAPA <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AA','PA'))
df.cat.espantarAIPI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AI','PI'))
df.cat.espantarPAPN <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PA','PN'))
df.cat.espantarPIPN <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.espantarAAAI$Rating) # = 6.024e-05
shapiro.test(df.cat.espantarPAPI$Rating) # = 8.542e-06
shapiro.test(df.cat.espantarAAPA$Rating) # = 0.000601
shapiro.test(df.cat.espantarAIPI$Rating) # = 4.53e-07
shapiro.test(df.cat.espantarPAPN$Rating) # = 2.136e-06
shapiro.test(df.cat.espantarPIPN$Rating) # = 3.234e-08


#Levene Test to test for variance among all verbs
#ESPANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI) # 0.8817
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI, center=mean) # 0.8141


#ESPANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI) # 0.0349 *
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI, center=mean) # 0.0032 **


#ESPANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA) # 0.08564 .
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA, center=mean) # 0.02014 *


#ESPANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI) # 0.4357
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI, center=mean) # 0.336


#ESPANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN) # 0.0008025 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN, center=mean) # 1.353e-05 ***


#ESPANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN) # 0.2965
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN, center=mean) # 0.1679

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.espantar <- subset(df.cat.SD, Verb == "E")
tapply(df.cat.espantar$Rating, list(df.cat.espantar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ESPANTAR AA & AI
wilcox.test(df.cat.espantarAAAI$Rating ~ df.cat.espantarAAAI$Sentencetype) # = 0.163


#ESPANTAR PA &PI
wilcox.test(df.cat.espantarPAPI$Rating ~ df.cat.espantarPAPI$Sentencetype) # = 0.006265


#ESPANTAR AA & PA
wilcox.test(df.cat.espantarAAPA$Rating ~ df.cat.espantarAAPA$Sentencetype) # = 0.2812


#ESPANTAR AI & PI
wilcox.test(df.cat.espantarAIPI$Rating ~ df.cat.espantarAIPI$Sentencetype) # = 0.5755  


#ESPANTAR PA & PN
wilcox.test(df.cat.espantarPAPN$Rating ~ df.cat.espantarPAPN$Sentencetype) # = 0.0007014


#ESPANTAR PI & PN
wilcox.test(df.cat.espantarPIPN$Rating ~ df.cat.espantarPIPN$Sentencetype) # = 0.4412

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AI&PI, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AA&PA
  - The means differ significantly in the following pairs:                PA&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AA&PA, AI&PI, PI&PN




MOLESTAR
```{r}

#Create relevant subsets to test for animacy effects throughout MOLESTAR (M)
df.cat.molestarAA <- subset(df.cat.allAA, Verb == "M")
df.cat.molestarAI <- subset(df.cat.allAI, Verb == "M")
df.cat.molestarPA <- subset(df.cat.allPA, Verb == "M")
df.cat.molestarPI <- subset(df.cat.allPI, Verb == "M")
df.cat.molestarPN <- subset(df.cat.allPN, Verb == "M")

```

```{r}
#Shapiro test to test for normal distribution among the MOLESTAR (M) subsets
shapiro.test(df.cat.molestarAA$Rating) # = 0.000998
shapiro.test(df.cat.molestarAI$Rating) # = 0.0002318
shapiro.test(df.cat.molestarPA$Rating) # = 0.05549 NORMAL
shapiro.test(df.cat.molestarPI$Rating) # = 1.945e-06
shapiro.test(df.cat.molestarPN$Rating) # = 0.02287

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.molestarAAAI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AA','AI'))
df.cat.molestarPAPI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PA','PI'))
df.cat.molestarAAPA <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AA','PA'))
df.cat.molestarAIPI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AI','PI'))
df.cat.molestarPAPN <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PA','PN'))
df.cat.molestarPIPN <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.molestarAAAI$Rating) # = 1.821e-06
shapiro.test(df.cat.molestarPAPI$Rating) # = 2.143e-05
shapiro.test(df.cat.molestarAAPA$Rating) # = 0.0007042
shapiro.test(df.cat.molestarAIPI$Rating) # = 2.607e-08
shapiro.test(df.cat.molestarPAPN$Rating) # = 0.002312
shapiro.test(df.cat.molestarPIPN$Rating) # = 3.392e-06


#Levene Test to test for variance among all verbs
#MOLESTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI) # 0.3372
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI, center=mean) # 0.1869


#MOLESTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI) # 0.03383 *
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI, center=mean) # 0.0244 *


#MOLESTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA) # 0.1414
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA, center=mean) # 0.08277 .


#MOLESTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI) # 0.8897
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI, center=mean) # 0.5486


#MOLESTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN) # 0.8081
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN, center=mean) # 0.7049


#MOLESTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN) # 0.0206 *
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN, center=mean) # 0.01284 *

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.molestar <- subset(df.cat.SD, Verb == "M")
tapply(df.cat.molestar$Rating, list(df.cat.molestar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#MOLESTAR AA & AI
wilcox.test(df.cat.molestarAAAI$Rating ~ df.cat.molestarAAAI$Sentencetype) # = 0.2895


#MOLESTAR PA &PI
wilcox.test(df.cat.molestarPAPI$Rating ~ df.cat.molestarPAPI$Sentencetype) # = 6.777e-05 


#MOLESTAR AA & PA
wilcox.test(df.cat.molestarAAPA$Rating ~ df.cat.molestarAAPA$Sentencetype) # = 0.0009531


#MOLESTAR AI & PI
wilcox.test(df.cat.molestarAIPI$Rating ~ df.cat.molestarAIPI$Sentencetype) # = 0.434


#MOLESTAR PA & PN
wilcox.test(df.cat.molestarPAPN$Rating ~ df.cat.molestarPAPN$Sentencetype) # = 0.2321 


#MOLESTAR PI & PN
wilcox.test(df.cat.molestarPIPN$Rating ~ df.cat.molestarPIPN$Sentencetype) # = 0.002927

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PI&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AA&PA (close), AI&PI, PA&PN
  - The means differ significantly in the following pairs:                PA&PI, AA&PA, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AI&PI, PA&PN



PREOCUPAR
```{r}

#Create relevant subsets to test for animacy effects throughout PREOCUPAR (P)
df.cat.preocuparAA <- subset(df.cat.allAA, Verb == "P")
df.cat.preocuparAI <- subset(df.cat.allAI, Verb == "P")
df.cat.preocuparPA <- subset(df.cat.allPA, Verb == "P")
df.cat.preocuparPI <- subset(df.cat.allPI, Verb == "P")
df.cat.preocuparPN <- subset(df.cat.allPN, Verb == "P")

```

```{r}
#Shapiro test to test for normal distribution among the PREOCUPAR (P) subsets
shapiro.test(df.cat.preocuparAA$Rating) # = 0.0002057
shapiro.test(df.cat.preocuparAI$Rating) # = 1.086e-07
shapiro.test(df.cat.preocuparPA$Rating) # = 1.846e-08
shapiro.test(df.cat.preocuparPI$Rating) # = 2.693e-09
shapiro.test(df.cat.preocuparPN$Rating) # = 4.32e-07

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.preocuparAAAI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AA','AI'))
df.cat.preocuparPAPI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PA','PI'))
df.cat.preocuparAAPA <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AA','PA'))
df.cat.preocuparAIPI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AI','PI'))
df.cat.preocuparPAPN <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PA','PN'))
df.cat.preocuparPIPN <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.preocuparAAAI$Rating) # = 3.511e-09
shapiro.test(df.cat.preocuparPAPI$Rating) # = 1.192e-12
shapiro.test(df.cat.preocuparAAPA$Rating) # = 1.31e-09
shapiro.test(df.cat.preocuparAIPI$Rating) # = 4.161e-12
shapiro.test(df.cat.preocuparPAPN$Rating) # = 3.509e-11
shapiro.test(df.cat.preocuparPIPN$Rating) # = 1.197e-11


#Levene Test to test for variance among all verbs
#PREOCUPAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI) # 0.003415 **
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI, center=mean) # 0.0002797 ***


#PREOCUPAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI) # 0.5602
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI, center=mean) # 0.2394


#PREOCUPAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA) # 0.001003 **
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA, center=mean) # 2.374e-05 ***


#PREOCUPAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI) # 0.2457
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI, center=mean) # 0.01696 *


#PREOCUPAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN) # 0.2252
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN, center=mean) # 0.01069 *


#PREOCUPAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN) # 0.1154
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN, center=mean) # 0.0009233 ***

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.preocupar <- subset(df.cat.SD, Verb == "P")
tapply(df.cat.preocupar$Rating, list(df.cat.preocupar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#PREOCUPAR AA & AI
wilcox.test(df.cat.preocuparAAAI$Rating ~ df.cat.preocuparAAAI$Sentencetype) # = 0.01387


#PREOCUPAR PA &PI
wilcox.test(df.cat.preocuparPAPI$Rating ~ df.cat.preocuparPAPI$Sentencetype) # = 0.5734


#PREOCUPAR AA & PA
wilcox.test(df.cat.preocuparAAPA$Rating ~ df.cat.preocuparAAPA$Sentencetype) # = 0.004231 


#PREOCUPAR AI & PI
wilcox.test(df.cat.preocuparAIPI$Rating ~ df.cat.preocuparAIPI$Sentencetype) # = 0.2985 


#PREOCUPAR PA & PN
wilcox.test(df.cat.preocuparPAPN$Rating ~ df.cat.preocuparPAPN$Sentencetype) # = 0.3486 


#PREOCUPAR PI & PN
wilcox.test(df.cat.preocuparPIPN$Rating ~ df.cat.preocuparPIPN$Sentencetype) # = 0.1508 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI, AA&PA
  - The variance does NOT differ significantly in the following pairs:    PA&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AI&PI, PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, AA&PA
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN


SORPRENDRE
```{r}

#Create relevant subsets to test for animacy effects throughout SORPRENDRE (S)
df.cat.sorprendreAA <- subset(df.cat.allAA, Verb == "S") # empty dataset
df.cat.sorprendreAI <- subset(df.cat.allAI, Verb == "S") # double the size (7 & 90) - delete 90?
df.cat.sorprendrePA <- subset(df.cat.allPA, Verb == "S")
df.cat.sorprendrePI <- subset(df.cat.allPI, Verb == "S")
df.cat.sorprendrePN <- subset(df.cat.allPN, Verb == "S")

```

```{r}
#Shapiro test to test for normal distribution among the SORPRENDRE (S) subsets
shapiro.test(df.cat.sorprendreAA$Rating) # empty dataset
shapiro.test(df.cat.sorprendreAI$Rating) # = 6.615e-06
shapiro.test(df.cat.sorprendrePA$Rating) # = 8.464e-05
shapiro.test(df.cat.sorprendrePI$Rating) # = 0.007656
shapiro.test(df.cat.sorprendrePN$Rating) # = 8.15e-05

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.sorprendreAAAI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AA','AI'))
df.cat.sorprendrePAPI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PA','PI'))
df.cat.sorprendreAAPA <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AA','PA'))
df.cat.sorprendreAIPI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AI','PI'))
df.cat.sorprendrePAPN <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PA','PN'))
df.cat.sorprendrePIPN <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.sorprendreAAAI$Rating) # = 1.805e-06
shapiro.test(df.cat.sorprendrePAPI$Rating) # = 3.322e-07
shapiro.test(df.cat.sorprendreAAPA$Rating) # = 5.524e-05
shapiro.test(df.cat.sorprendreAIPI$Rating) # = 1.999e-08
shapiro.test(df.cat.sorprendrePAPN$Rating) # = 1.261e-08
shapiro.test(df.cat.sorprendrePIPN$Rating) # = 4.039e-08


#Levene Test to test for variance among all verbs
#SORPRENDRE verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI, center=mean) 


#SORPRENDRE verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI) # 0.8953
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI, center=mean) # 0.8768


#SORPRENDRE verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA, center=mean) 


#SORPRENDRE verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI) # 0.3832
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI, center=mean) # 0.2514


#SORPRENDRE verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN) # 0.7616
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN, center=mean) # 0.8326


#SORPRENDRE verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN) # 0.8353
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN, center=mean) # 0.7072

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.sorprendre <- subset(df.cat.SD, Verb == "S")
tapply(df.cat.sorprendre$Rating, list(df.cat.sorprendre$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#SORPRENDRE AA & AI
wilcox.test(df.cat.sorprendreAAAI$Rating ~ df.cat.sorprendreAAAI$Sentencetype) # Doesn't work because AA set is empty


#SORPRENDRE PA &PI
wilcox.test(df.cat.sorprendrePAPI$Rating ~ df.cat.sorprendrePAPI$Sentencetype) # = 0.8062


#SORPRENDRE AA & PA
wilcox.test(df.cat.sorprendreAAPA$Rating ~ df.cat.sorprendreAAPA$Sentencetype) # Doesn't work because AA set is empty


#SORPRENDRE AI & PI
wilcox.test(df.cat.sorprendreAIPI$Rating ~ df.cat.sorprendreAIPI$Sentencetype) # = 0.8003


#SORPRENDRE PA & PN
wilcox.test(df.cat.sorprendrePAPN$Rating ~ df.cat.sorprendrePAPN$Sentencetype) # = 0.2927 


#SORPRENDRE PI & PN
wilcox.test(df.cat.sorprendrePIPN$Rating ~ df.cat.sorprendrePIPN$Sentencetype) # = 0.2066

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AI&PI,PA&PN, PI&PN
  - The means differ significantly in the following pairs:                NONE
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN
  - AA&AI and AA&PA could not be tested because of missing data



ENTRISTIR
```{r}

#Create relevant subsets to test for animacy effects throughout ENTRISTIR (T)
df.cat.entristirAA <- subset(df.cat.allAA, Verb == "T")
df.cat.entristirAI <- subset(df.cat.allAI, Verb == "T")
df.cat.entristirPA <- subset(df.cat.allPA, Verb == "T")
df.cat.entristirPI <- subset(df.cat.allPI, Verb == "T")
df.cat.entristirPN <- subset(df.cat.allPN, Verb == "T")

```

```{r}
#Shapiro test to test for normal distribution among the ENTRISTIR (T) subsets
shapiro.test(df.cat.entristirAA$Rating) # = 0.001761
shapiro.test(df.cat.entristirAI$Rating) # = 0.002674
shapiro.test(df.cat.entristirPA$Rating) # = 9.147e-06
shapiro.test(df.cat.entristirPI$Rating) # = 2.065e-07
shapiro.test(df.cat.entristirPN$Rating) # = 4.735e-05

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.entristirAAAI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AA','AI'))
df.cat.entristirPAPI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PA','PI'))
df.cat.entristirAAPA <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AA','PA'))
df.cat.entristirAIPI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AI','PI'))
df.cat.entristirPAPN <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PA','PN'))
df.cat.entristirPIPN <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.entristirAAAI$Rating) # = 2.083e-05
shapiro.test(df.cat.entristirPAPI$Rating) # = 1.028e-09
shapiro.test(df.cat.entristirAAPA$Rating) # = 3.829e-07
shapiro.test(df.cat.entristirAIPI$Rating) # = 9.707e-08
shapiro.test(df.cat.entristirPAPN$Rating) # = 2.263e-08
shapiro.test(df.cat.entristirPIPN$Rating) # = 3.546e-09


#Levene Test to test for variance among all verbs
#ENTRISTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI) # 1
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI, center=mean) # 0.9115


#ENTRISTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPI) # 0.4637
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPI, center=mean) # 0.3873


#ENTRISTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA) # 0.01977 *
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA, center=mean) # 0.003093 **


#ENTRISTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI) # 0.006368 **
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI, center=mean) # 0.0003826 ***


#ENTRISTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN) # 0.08631 .
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN, center=mean) # 0.01359 *


#ENTRISTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN) # 0.02371 *
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN, center=mean) # 0.002806 **

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.entristir <- subset(df.cat.SD, Verb == "T")
tapply(df.cat.entristir$Rating, list(df.cat.entristir$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ENTRISTIR AA & AI
wilcox.test(df.cat.entristirAAAI$Rating ~ df.cat.entristirAAAI$Sentencetype) # = 0.6968


#ENTRISTIR PA &PI
wilcox.test(df.cat.entristirPAPI$Rating ~ df.cat.entristirPAPI$Sentencetype) # = 0.3258 


#ENTRISTIR AA & PA
wilcox.test(df.cat.entristirAAPA$Rating ~ df.cat.entristirAAPA$Sentencetype) # = 0.04916


#ENTRISTIR AI & PI
wilcox.test(df.cat.entristirAIPI$Rating ~ df.cat.entristirAIPI$Sentencetype) # = 0.001465


#ENTRISTIR PA & PN
wilcox.test(df.cat.entristirPAPN$Rating ~ df.cat.entristirPAPN$Sentencetype) # = 0.2386


#All verbs PI & PN
wilcox.test(df.cat.entristirPIPN$Rating ~ df.cat.entristirPIPN$Sentencetype) # = 0.04157

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&PA, AI&PI; PI&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PN
  - The means differ significantly in the following pairs:                AA&PA, AI&PI, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, PA&PI, PA&PN



ESTRANYAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESTRANYAR (U)
df.cat.estranyarAA <- subset(df.cat.allAA, Verb == "U")
df.cat.estranyarAI <- subset(df.cat.allAI, Verb == "U")
df.cat.estranyarPA <- subset(df.cat.allPA, Verb == "U")
df.cat.estranyarPI <- subset(df.cat.allPI, Verb == "U")
df.cat.estranyarPN <- subset(df.cat.allPN, Verb == "U")

```

```{r}
#Shapiro test to test for normal distribution among the ESTRANYAR (U) subsets
shapiro.test(df.cat.estranyarAA$Rating) # = 0.003407
shapiro.test(df.cat.estranyarAI$Rating) # = 0.001098
shapiro.test(df.cat.estranyarPA$Rating) # = 0.02182
shapiro.test(df.cat.estranyarPI$Rating) # = 3.302e-05
shapiro.test(df.cat.estranyarPN$Rating) # = 1.395e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.estranyarAAAI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AA','AI'))
df.cat.estranyarPAPI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PA','PI'))
df.cat.estranyarAAPA <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AA','PA'))
df.cat.estranyarAIPI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AI','PI'))
df.cat.estranyarPAPN <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PA','PN'))
df.cat.estranyarPIPN <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.estranyarAAAI$Rating) # = 5.488e-05
shapiro.test(df.cat.estranyarPAPI$Rating) # = 1.543e-05
shapiro.test(df.cat.estranyarAAPA$Rating) # = 0.0002526
shapiro.test(df.cat.estranyarAIPI$Rating) # = 2.583e-05
shapiro.test(df.cat.estranyarPAPN$Rating) # = 1.717e-06
shapiro.test(df.cat.estranyarPIPN$Rating) # = 5.788e-09


#Levene Test to test for variance among all verbs
#ESTRANYAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI) # 0.004517 **
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI, center=mean) # 0.004019 **


#ESTRANYAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI) # 0.216
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI, center=mean) # 0.1412


#ESTRANYAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA) # 0.2439
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA, center=mean) # 0.2413


#ESTRANYAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI) # 0.7695
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI, center=mean) # 0.6419


#ESTRANYAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN) # 7.8e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN, center=mean) # 1.987e-06 ***


#ESTRANYAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN) # 0.07776 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN, center=mean) # 0.005159 **

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.estranyar <- subset(df.cat.SD, Verb == "U")
tapply(df.cat.estranyar$Rating, list(df.cat.estranyar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there's a significant difference between the two groups

#ESTARNYAR AA & AI
wilcox.test(df.cat.estranyarAAAI$Rating ~ df.cat.estranyarAAAI$Sentencetype) # = 0.03955


#ESTRANYAR PA &PI
wilcox.test(df.cat.estranyarPAPI$Rating ~ df.cat.estranyarPAPI$Sentencetype) # = 0.01291


#ESTRANYAR AA & PA
wilcox.test(df.cat.estranyarAAPA$Rating ~ df.cat.estranyarAAPA$Sentencetype) # = 0.9562


#ESTRANYAR AI & PI
wilcox.test(df.cat.estranyarAIPI$Rating ~ df.cat.estranyarAIPI$Sentencetype) # = 2e-05


#ESTRANYAR PA & PN
wilcox.test(df.cat.estranyarPAPN$Rating ~ df.cat.estranyarPAPN$Sentencetype) # = 8.56e-05


#ESTRANYAR PI & PN
wilcox.test(df.cat.estranyarPIPN$Rating ~ df.cat.estranyarPIPN$Sentencetype) # = 0.1383

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AA&PA, AI&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PI&PN
  - The means differ significantly in the following pairs:                AA&AI, PA&PI, AI&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&PA, PI&PN