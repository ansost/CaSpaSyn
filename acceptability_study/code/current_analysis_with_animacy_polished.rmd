---
title: '"Acceptabiliy Analysis for Catalan and Spanish Ratings"'
author: "ASSASSMG"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r, setup, include=FALSE}
# The following line sets the [working directory](https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html) for reading in the files. 
# Exchange the part before `/CaSpaSyn/code` with wherever you have the copy of the repository.
knitr::opts_knit$set(root.dir = "~/repos/CaSpaSyn/code/")

# Don't include warnings and messages in the rendered document.
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r packages, include=FALSE}
# Load/install libraries. 
#install.packages("tidyverse")
packages <- c("tidyverse", "lubridate", "gridExtra", "car", "namer", "dplyr", "magrittr", "ggplot2")

installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
	install.packages(packages[!installed_packages])
}

invisible(lapply(packages, library, character.only = TRUE))
```

# Data Exploration

```{r loadData}
# Load data.
df.cat.initial <- read_csv("../data/Catalan_ASSASSMG.csv")
df.spa.initial <- read_csv("../data/Spanish_ASSASSMG.csv")

# Print data overview.
str(df.cat.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
str(df.spa.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
```

Make sure that the ratings are treated as numerical data, not strings. 
```{r dataTreatment, include = FALSE}
df.cat <- transform(df.cat.initial, Rating = as.numeric(Rating))
df.spa <- transform(df.spa.initial, Rating = as.numeric(Rating))
```

## Overall Rating Distribution

Ratings are very skewed towards the high end of the scale.

```{r ratingBoxplot, echo=FALSE}
box.spa <- ggplot(df.spa, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) + # display all x axis ticks
    ggtitle("Spanish Ratings")

box.cat <- ggplot(df.cat, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) + # display all x axis ticks 
    ggtitle("Catalan Ratings")

grid.arrange(box.spa, box.cat, ncol=2)
#ggsave(filename = "../figures/rating_count_distribution.png")
```

Beide DatensÃ¤tze sind nicht normalverteilt:

```{r normalityAllRatings, echo=FALSE}
shapiro.test(df.cat$Rating)
shapiro.test(df.spa$Rating)
```

## Outlier Inspection

### Participants

Subset data by participants

```{r}
participants.spa <- df.spa %>%
    select(Code, Rating) %>%
    group_by(Code)

participants.cat <- df.cat %>%
    select(Code, Rating) %>%
    group_by(Code)
```

Plots of rating distribution per participant.

Catalan participants:

```{r}
ggplot(data = participants.cat, aes(Rating)) +
  geom_histogram(binwidth=.5, na.rm = TRUE, fill="#08c7c4", color="#e9ecef") +
  labs(title = "Rating distribution per participant - Catalan",
  y = "Rating count", x = "Rating scale point") + 
  scale_x_continuous("Rating", labels = as.character(participants.cat$Rating), breaks = participants.cat$Rating) +
  facet_wrap(~ Code)
ggsave("../figures/ratingDistributionCatalan.png")
```

Spanish participants:

```{r}
ggplot(data = participants.spa, aes(Rating)) +
  geom_histogram(binwidth=.5, na.rm = TRUE)+
  labs(title = "Rating distribution per participant - Castillian",
  y = "Rating count", x = "Rating scale point") + 
  scale_x_continuous("Rating", labels = as.character(participants.spa$Rating), breaks = participants.spa$Rating) +
  facet_wrap(~ Code)
#ggsave("../figures/ratingDistributionCastillian.png")
```

### Survey Completion Time

Check for completion times 1 standard deviation away from average survey
completion time
([source](https://academic.oup.com/poq/article/72/5/914/1832496#28138951)).

Calculate survey duration.

```{r surveytime, results = "hide", echo = FALSE}
df.cat <- df.cat %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))
df.spa <- df.spa %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))

participants.cat$surveyduration <- df.cat$surveyduration
participants.spa$surveyduration <- df.spa$surveyduration
```

Plot survey durations per participant. 

```{r}
ggplot(participants.spa, aes(x=reorder(Code,surveyduration,na.rm = TRUE), y=surveyduration)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Survey duration per participant - Castillian",
  y = "Survey duration", x = "Code")
#ggsave("../figures/surveydurParticipantsCastillian.png")


ggplot(participants.cat, aes(x=reorder(Code,surveyduration,na.rm = TRUE), y=surveyduration)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Survey duration per participant - Catalan",
  y = "Survey duration", x = "Code")
#ggsave("../figures/surveydurParticipantsCatalan.png")
```


```{r}
mean(df.cat$surveyduration) + 1.5 * sd(df.cat$surveyduration) 
mean(df.cat$surveyduration) + 1 * sd(df.cat$surveyduration) 
mean(df.spa$surveyduration) - 1.5 * sd(df.spa$surveyduration)  
mean(df.spa$surveyduration) - 1 * sd(df.spa$surveyduration)  
```
```{r}
mean(df.spa$surveyduration) + 1.5 *sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) + 1 * sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) - 1.5 * sd(df.spa$surveyduration) 
mean(df.spa$surveyduration) - 1 * sd(df.spa$surveyduration) 
```

```{r exclusionTimes}
nrow(subjTimes.cat %>% filter(surveyduration < 10 | surveyduration > 17)) # 7/25
nrow(subjTimes.cat %>% filter(surveyduration < 8 | surveyduration > 19)) # 2/25

nrow(subjTimes.spa %>% filter(surveyduration < 8 | surveyduration > 19)) # 10/25 
nrow(subjTimes.spa %>% filter(surveyduration < 6 | surveyduration > 21)) # 3/26
```


# Animacy Comparison 1.5 SD

For the category "all verbs", as well as each individual verb (encantar, divertir, molestar, espantar,...), you will find the following code-blocks:

1. Create relevant subsets for Shapiro Test to test for normal distribution
2. Shapiro Tests for subsets created in 1.
3. New subsets to compare the relevant animacy properties; Shapiro Tests conducted with those subsets (not sure if that was necessary, but bettr safe than sorry), Levene Test
4. Mann-Whitney U Test & means output via tapply
5. First comments

A note on the Levene Test: 
Depending on whether the median or the mean is used as center, the resulting numbers differ by quite a lot.
As far as I understood, the median version is more robust against not normally distributed Data.


**ALL VERBS**

```{r}

#Subset with 1.5 SD taken into account
df.cat.SD <-  subset(df.cat, surveyduration > 7 & surveyduration < 18) 


#Create relevant subsets to test for animacy effects throughout all verbs
df.cat.allAA <- subset(df.cat.SD, Sentencetype == "AA")
df.cat.allAI <- subset(df.cat.SD, Sentencetype == "AI")
df.cat.allPA <- subset(df.cat.SD, Sentencetype == "PA")
df.cat.allPI <- subset(df.cat.SD, Sentencetype == "PI")
df.cat.allPN <- subset(df.cat.SD, Sentencetype == "PN")

```

```{r}

#Shapiro Test to test for normal distribution (anything below 0.05 is not normal)
shapiro.test(df.cat$Rating)  # <2.2e-16 (not normal distribution)

#Shapiro test to test for normal distribution among the Sentencytype subsets

shapiro.test(df.cat.allAA$Rating) # = 8.842e-12 
shapiro.test(df.cat.allAI$Rating) # = 4.049e-16
shapiro.test(df.cat.allPA$Rating) # = 1.11e-13
shapiro.test(df.cat.allPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPN$Rating) # < 2.2e-16

```

```{r}

#Levene test

library(car) #necessary for levene test to work

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.allAAAI <- subset(df.cat.SD, Sentencetype %in% c('AA','AI'))
df.cat.allPAPI <- subset(df.cat.SD, Sentencetype %in% c('PA','PI'))
df.cat.allAAPA <- subset(df.cat.SD, Sentencetype %in% c('AA','PA'))
df.cat.allAIPI <- subset(df.cat.SD, Sentencetype %in% c('AI','PI'))
df.cat.allPAPN <- subset(df.cat.SD, Sentencetype %in% c('PA','PN'))
df.cat.allPIPN <- subset(df.cat.SD, Sentencetype %in% c('PI','PN'))
df.cat.allAAPI <- subset(df.cat.SD, Sentencetype %in% c('AA','PI'))
df.cat.allAIPA <- subset(df.cat.SD, Sentencetype %in% c('AI','PA'))

#shapiro tests for new subsets, just in case (unsurprisingly, none are normally distributed)

shapiro.test(df.cat.allAAAI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allAAPA$Rating) # < 2.2e-16
shapiro.test(df.cat.allAIPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPN$Rating) # < 2.2e-16
shapiro.test(df.cat.allPIPN$Rating) # < 2.2e-16
shapiro.test(df.cat.allAAPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allAIPA$Rating) # < 2.2e-16



#Levene Test to test for variance among all verbs
#"*" mark how significant the variance is
#The more "*", the more significant

#All verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI) # 0.3157
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI, center=mean) # 0.5318


#All verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI) # 0.001179 **
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI, center=mean) # 0.0001041 ***


#All verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA) # 0.4127
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA, center=mean) # 0.1589


#All verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI) # 0.06906 .
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI, center=mean) # 0.04788 *


#All verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN) # 0.003112 **
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN, center=mean) # 0.0002256 ***


#All verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN) # 0.764
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN, center=mean) # 0.7087


#All verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPI) # 0.01428 *
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPI, center=mean) # 0.01584 *


#All verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPA) # 0.05559 .
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPA, center=mean) # 0.03107 *

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

tapply(df.cat.SD$Rating, list(df.cat.SD$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#All verbs AA & AI
wilcox.test(df.cat.allAAAI$Rating ~ df.cat.allAAAI$Sentencetype) # = 0.05504



#All verbs PA &PI
wilcox.test(df.cat.allPAPI$Rating ~ df.cat.allPAPI$Sentencetype) # = 0.0001806


#All verbs AA & PA
wilcox.test(df.cat.allAAPA$Rating ~ df.cat.allAAPA$Sentencetype) # = 0.9349


#All verbs AI & PI
wilcox.test(df.cat.allAIPI$Rating ~ df.cat.allAIPI$Sentencetype) # = 0.02719


#All verbs PA & PN
wilcox.test(df.cat.allPAPN$Rating ~ df.cat.allPAPN$Sentencetype) # = 0.0006221 


#All verbs PI & PN
wilcox.test(df.cat.allPIPN$Rating ~ df.cat.allPIPN$Sentencetype) # = 0.7076 


#All verbs AA & PI
wilcox.test(df.cat.allAAPI$Rating ~ df.cat.allAAPI$Sentencetype) # = 7.713e-05


#All verbs AI & PA
wilcox.test(df.cat.allAIPA$Rating ~ df.cat.allAIPA$Sentencetype) # = 0.07399

```


Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AA&PA, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AI&PI 
  - The means differ significantly in the following pairs:                PA&PI, AI&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AA&PA, PI&PN
  



# PER VERB

#encantar (C)
#divertir (D)
#espanatr (E)
#molestar (M)
#preocupar (P)
#sorprendre (S)
#entristir (T)
#estranyar (U)


ENCANTAR
```{r}
#Create relevant subsets to test for animacy effects throughout ENCANTAR (C)
df.cat.encantarAA <- subset(df.cat.allAA, Verb == "C")
df.cat.encantarAI <- subset(df.cat.allAI, Verb == "C")
df.cat.encantarPA <- subset(df.cat.allPA, Verb == "C")
df.cat.encantarPI <- subset(df.cat.allPI, Verb == "C")
df.cat.encantarPN <- subset(df.cat.allPN, Verb == "C")

```

```{r}
#Shapiro test to test for normal distribution among the ENCANTAR (C) subsets
shapiro.test(df.cat.encantarAA$Rating) # = 0.00235
shapiro.test(df.cat.encantarAI$Rating) # = 0.01751
shapiro.test(df.cat.encantarPA$Rating) # = 0.02915
shapiro.test(df.cat.encantarPI$Rating) # = 0.005413
shapiro.test(df.cat.encantarPN$Rating) # = 0.01602


```
 
```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.encantarAAAI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AA','AI'))
df.cat.encantarPAPI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PA','PI'))
df.cat.encantarAAPA <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AA','PA'))
df.cat.encantarAIPI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AI','PI'))
df.cat.encantarPAPN <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PA','PN'))
df.cat.encantarPIPN <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('PI','PN'))
df.cat.encantarAAPI <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AA','PI'))
df.cat.encantarAIPA <- subset(df.cat.SD, Verb=='C' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.encantarAAAI$Rating) # = 9.991e-05
shapiro.test(df.cat.encantarPAPI$Rating) # = 0.0002416
shapiro.test(df.cat.encantarAAPA$Rating) # = 0.0003093
shapiro.test(df.cat.encantarAIPI$Rating) # = 0.0006109
shapiro.test(df.cat.encantarPAPN$Rating) # = 0.0009694
shapiro.test(df.cat.encantarPIPN$Rating) # = 0.0004349
shapiro.test(df.cat.encantarAAPI$Rating) # = 0.0001067
shapiro.test(df.cat.encantarAIPA$Rating) # = 0.001691


#Levene Test to test for variance among all verbs
#ENCANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI) # 0.1473
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI, center=mean) # 0.08142 .


#ENCANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI) # 1?
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI, center=mean) # 0.8443


#ENCANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA) # 0.4566
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA, center=mean) # 0.341


#ENCANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI) # 0.4232
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI, center=mean) # 0.4634


#ENCANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN) # 0.7431
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN, center=mean) # 0.6349


#ENCANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN) # 0.7366
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN, center=mean) # 0.5177


#ENCANTAR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPI) # 0.4413
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPI, center=mean) # 0.278


#ENCANTAR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPA) # 0.44
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPA, center=mean) # 0.34


```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.encantar <- subset(df.cat.SD, Verb == "C")
tapply(df.cat.encantar$Rating, list(df.cat.encantar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ENCANTAR AA & AI
wilcox.test(df.cat.encantarAAAI$Rating ~ df.cat.encantarAAAI$Sentencetype) # = 0.9287


#ENCANTAR PA &PI
wilcox.test(df.cat.encantarPAPI$Rating ~ df.cat.encantarPAPI$Sentencetype) # = 0.4388


#ENCANTAR AA & PA
wilcox.test(df.cat.encantarAAPA$Rating ~ df.cat.encantarAAPA$Sentencetype) # = 0.05673


#ENCANTAR AI & PI
wilcox.test(df.cat.encantarAIPI$Rating ~ df.cat.encantarAIPI$Sentencetype) # = 0.002651



#ENCANTAR PA & PN
wilcox.test(df.cat.encantarPAPN$Rating ~ df.cat.encantarPAPN$Sentencetype) # = 0.2025


#ENCANTAR PI & PN
wilcox.test(df.cat.encantarPIPN$Rating ~ df.cat.encantarPIPN$Sentencetype) # = 0.04668


#ENCANTAR AA & PI
wilcox.test(df.cat.encantarAAPI$Rating ~ df.cat.encantarAAPI$Sentencetype) # = 0.01358


#ENCANTAR AI & PA
wilcox.test(df.cat.encantarAIPA$Rating ~ df.cat.encantarAIPA$Sentencetype) # = 0.01477

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI AA&PA, AI&PI, PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AI&PI, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, PA&PI, AA&PA, PA&PN




DIVERTIR

```{r}

#Create relevant subsets to test for animacy effects throughout DIVERTIR (D)
df.cat.divertirAA <- subset(df.cat.allAA, Verb == "D")
df.cat.divertirAI <- subset(df.cat.allAI, Verb == "D")
df.cat.divertirPA <- subset(df.cat.allPA, Verb == "D")
df.cat.divertirPI <- subset(df.cat.allPI, Verb == "D")
df.cat.divertirPN <- subset(df.cat.allPN, Verb == "D")

```

```{r}
#Shapiro test to test for normal distribution among the DIVERTIR (D) subsets
shapiro.test(df.cat.divertirAA$Rating) # = 0.001731
shapiro.test(df.cat.divertirAI$Rating) # = 5.371e-07
shapiro.test(df.cat.divertirPA$Rating) # = 3.152e-05
shapiro.test(df.cat.divertirPI$Rating) # = 7.568e-06
shapiro.test(df.cat.divertirPN$Rating) # = 0.0003136

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.divertirAAAI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AA','AI'))
df.cat.divertirPAPI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PA','PI'))
df.cat.divertirAAPA <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AA','PA'))
df.cat.divertirAIPI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AI','PI'))
df.cat.divertirPAPN <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PA','PN'))
df.cat.divertirPIPN <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('PI','PN'))
df.cat.divertirAAPI <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AA','PI'))
df.cat.divertirAIPA <- subset(df.cat.SD, Verb=='D' & Sentencetype %in% c('AI','PA'))

#shapiro tests for new subsets
shapiro.test(df.cat.divertirAAAI$Rating) # = 1.33e-07
shapiro.test(df.cat.divertirPAPI$Rating) # = 1.603e-08
shapiro.test(df.cat.divertirAAPA$Rating) # = 4.205e-06
shapiro.test(df.cat.divertirAIPI$Rating) # = 1.712e-09
shapiro.test(df.cat.divertirPAPN$Rating) # = 1.743e-07
shapiro.test(df.cat.divertirPIPN$Rating) # = 2.184e-07
shapiro.test(df.cat.divertirAAPI$Rating) # = 6.999e-07
shapiro.test(df.cat.divertirAIPA$Rating) # = 3.071e-09


#Levene Test to test for variance among all verbs
#DIVERTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI) # 6.125e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI, center=mean) # 4.158e-05 ***


#DIVERTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI) # 0.2243
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI, center=mean) # 0.03017 *


#DIVERTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA) # 0.4425
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA, center=mean) # 0.6182


#DIVERTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI) # 0.4514
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI, center=mean) # 0.4195


#DIVERTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN) # 0.3197
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN, center=mean) # 0.01743 *


#DIVERTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN) # 0.5532
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN, center=mean) # 0.9856


#DIVERTIR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPI) # 0.004059 **
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPI, center=mean) # 0.001582 **


#DIVERTIR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPA) # 0.07034 .
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPA, center=mean) # 0.003944 **

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.divertir <- subset(df.cat.SD, Verb == "D")
tapply(df.cat.divertir$Rating, list(df.cat.divertir$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#DIVERTIR AA & AI
wilcox.test(df.cat.divertirAAAI$Rating ~ df.cat.divertirAAAI$Sentencetype) # = 0.002981


#DIVERTIR PA &PI
wilcox.test(df.cat.divertirPAPI$Rating ~ df.cat.divertirPAPI$Sentencetype) # = 0.4371


#DIVERTIR AA & PA
wilcox.test(df.cat.divertirAAPA$Rating ~ df.cat.divertirAAPA$Sentencetype) # = 0.1718


#DIVERTIR AI & PI
wilcox.test(df.cat.divertirAIPI$Rating ~ df.cat.divertirAIPI$Sentencetype) # = 0.39


#DIVERTIR PA & PN
wilcox.test(df.cat.divertirPAPN$Rating ~ df.cat.divertirPAPN$Sentencetype) # = 0.9715 


#DIVERTIR PI & PN
wilcox.test(df.cat.divertirPIPN$Rating ~ df.cat.divertirPIPN$Sentencetype) # = 0.3591


#DIVERTIR AA & PI
wilcox.test(df.cat.divertirAAPI$Rating ~ df.cat.divertirAAPI$Sentencetype) # = 0.02136


#DIVERTIR AI & PA
wilcox.test(df.cat.divertirAIPA$Rating ~ df.cat.divertirAIPA$Sentencetype) # = 0.1296

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI
  - The variance does NOT differ significantly in the following pairs:    AA&PA, AI&PI, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PI, PA&PN
  - The means differ significantly in the following pairs:                AA&AI
  - The means do NOT differ significantly in the following pairs:         PA&PI, AA&PA, AI&PI, PA&PN, PI&PN



ESPANTAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESPANTAR (E)
df.cat.espantarAA <- subset(df.cat.allAA, Verb == "E")
df.cat.espantarAI <- subset(df.cat.allAI, Verb == "E")
df.cat.espantarPA <- subset(df.cat.allPA, Verb == "E")
df.cat.espantarPI <- subset(df.cat.allPI, Verb == "E")
df.cat.espantarPN <- subset(df.cat.allPN, Verb == "E")

```

```{r}
#Shapiro test to test for normal distribution among the ESPANTAR (E) subsets
shapiro.test(df.cat.espantarAA$Rating) # = 0.01114
shapiro.test(df.cat.espantarAI$Rating) # = 0.0001301
shapiro.test(df.cat.espantarPA$Rating) # = 0.01954
shapiro.test(df.cat.espantarPI$Rating) # = 2.43e-05
shapiro.test(df.cat.espantarPN$Rating) # = 1.489e-05

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.espantarAAAI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AA','AI'))
df.cat.espantarPAPI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PA','PI'))
df.cat.espantarAAPA <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AA','PA'))
df.cat.espantarAIPI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AI','PI'))
df.cat.espantarPAPN <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PA','PN'))
df.cat.espantarPIPN <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('PI','PN'))
df.cat.espantarAAPI <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AA','PI'))
df.cat.espantarAIPA <- subset(df.cat.SD, Verb=='E' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.espantarAAAI$Rating) # = 1.141e-05
shapiro.test(df.cat.espantarPAPI$Rating) # = 5.417e-06
shapiro.test(df.cat.espantarAAPA$Rating) # = 0.0002917
shapiro.test(df.cat.espantarAIPI$Rating) # = 1.243e-07
shapiro.test(df.cat.espantarPAPN$Rating) # = 1.065e-06
shapiro.test(df.cat.espantarPIPN$Rating) # = 1.598e-08
shapiro.test(df.cat.espantarAAPI$Rating) # = 4.05e-06
shapiro.test(df.cat.espantarAIPA$Rating) # = 1.697e-05


#Levene Test to test for variance among all verbs
#ESPANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI) # 1
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI, center=mean) # 0.8303


#ESPANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI) # 0.01551 *
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI, center=mean) # 0.0006775 ***


#ESPANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA) # 0.0384 *
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA, center=mean) #  0.007046 **


#ESPANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI) # 0.5836
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI, center=mean) # 0.3006


#ESPANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN) # 0.000129 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN, center=mean) # 7.963e-07 ***


#ESPANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN) # 0.2464
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN, center=mean) # 0.1345


#ESPANTAR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPI) # 0.503
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPI, center=mean) # 0.4169


#ESPANTAR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPA) # 0.08667 .
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPA, center=mean) # 0.01134 *


```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.espantar <- subset(df.cat.SD, Verb == "E")
tapply(df.cat.espantar$Rating, list(df.cat.espantar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ESPANTAR AA & AI
wilcox.test(df.cat.espantarAAAI$Rating ~ df.cat.espantarAAAI$Sentencetype) # = 0.1379


#ESPANTAR PA &PI
wilcox.test(df.cat.espantarPAPI$Rating ~ df.cat.espantarPAPI$Sentencetype) # = 0.004485


#ESPANTAR AA & PA
wilcox.test(df.cat.espantarAAPA$Rating ~ df.cat.espantarAAPA$Sentencetype) # = 0.1676


#ESPANTAR AI & PI
wilcox.test(df.cat.espantarAIPI$Rating ~ df.cat.espantarAIPI$Sentencetype) # = 0.7286  


#ESPANTAR PA & PN
wilcox.test(df.cat.espantarPAPN$Rating ~ df.cat.espantarPAPN$Sentencetype) # = 0.0004053


#ESPANTAR PI & PN
wilcox.test(df.cat.espantarPIPN$Rating ~ df.cat.espantarPIPN$Sentencetype) # = 0.397


#ESPANTAR AA & PI
wilcox.test(df.cat.espantarAAPI$Rating ~ df.cat.espantarAAPI$Sentencetype) # = 0.04241


#ESPANTAR AI & PA
wilcox.test(df.cat.espantarAIPA$Rating ~ df.cat.espantarAIPA$Sentencetype) # = 0.01295

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AI&PI, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AA&PA
  - The means differ significantly in the following pairs:                PA&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AA&PA, AI&PI, PI&PN




MOLESTAR
```{r}

#Create relevant subsets to test for animacy effects throughout MOLESTAR (M)
df.cat.molestarAA <- subset(df.cat.allAA, Verb == "M")
df.cat.molestarAI <- subset(df.cat.allAI, Verb == "M")
df.cat.molestarPA <- subset(df.cat.allPA, Verb == "M")
df.cat.molestarPI <- subset(df.cat.allPI, Verb == "M")
df.cat.molestarPN <- subset(df.cat.allPN, Verb == "M")

```

```{r}
#Shapiro test to test for normal distribution among the MOLESTAR (M) subsets
shapiro.test(df.cat.molestarAA$Rating) # = 0.000445
shapiro.test(df.cat.molestarAI$Rating) # = 6.7e-05
shapiro.test(df.cat.molestarPA$Rating) # = 0.05503 NORMAL
shapiro.test(df.cat.molestarPI$Rating) # = 9.002e-07
shapiro.test(df.cat.molestarPN$Rating) # = 0.007846

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.molestarAAAI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AA','AI'))
df.cat.molestarPAPI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PA','PI'))
df.cat.molestarAAPA <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AA','PA'))
df.cat.molestarAIPI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AI','PI'))
df.cat.molestarPAPN <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PA','PN'))
df.cat.molestarPIPN <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('PI','PN'))
df.cat.molestarAAPI <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AA','PI'))
df.cat.molestarAIPA <- subset(df.cat.SD, Verb=='M' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.molestarAAAI$Rating) # = 4.475e-07
shapiro.test(df.cat.molestarPAPI$Rating) # = 5.737e-06
shapiro.test(df.cat.molestarAAPA$Rating) # = 0.0001935
shapiro.test(df.cat.molestarAIPI$Rating) # = 6.952e-09
shapiro.test(df.cat.molestarPAPN$Rating) # = 0.0007767
shapiro.test(df.cat.molestarPIPN$Rating) # = 5.44e-07
shapiro.test(df.cat.molestarAAPI$Rating) # = 3.47e-08
shapiro.test(df.cat.molestarAIPA$Rating) # = 3.404e-05


#Levene Test to test for variance among all verbs
#MOLESTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI) # 0.2216
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI, center=mean) # 0.1222


#MOLESTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI) # 0.005177 **
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI, center=mean) # 0.009927 **


#MOLESTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA) # 0.04533 *
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA, center=mean) # 0.05818 .


#MOLESTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI) # 0.8948
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI, center=mean) # 0.555


#MOLESTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN) # 0.8012
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN, center=mean) # 0.7074


#MOLESTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN) # 0.005984 **
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN, center=mean) # 0.003378 **


#MOLESTAR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPI) # 0.2465
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPI, center=mean) # 0.4295


#MOLESTAR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPA) # 0.001833 **
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPA, center=mean) # 0.000534 ***

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.molestar <- subset(df.cat.SD, Verb == "M")
tapply(df.cat.molestar$Rating, list(df.cat.molestar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#MOLESTAR AA & AI
wilcox.test(df.cat.molestarAAAI$Rating ~ df.cat.molestarAAAI$Sentencetype) # = 0.2967


#MOLESTAR PA &PI
wilcox.test(df.cat.molestarPAPI$Rating ~ df.cat.molestarPAPI$Sentencetype) # = 5.394e-05


#MOLESTAR AA & PA
wilcox.test(df.cat.molestarAAPA$Rating ~ df.cat.molestarAAPA$Sentencetype) # = 0.0014


#MOLESTAR AI & PI
wilcox.test(df.cat.molestarAIPI$Rating ~ df.cat.molestarAIPI$Sentencetype) # = 0.4752


#MOLESTAR PA & PN
wilcox.test(df.cat.molestarPAPN$Rating ~ df.cat.molestarPAPN$Sentencetype) # = 0.1988 


#MOLESTAR PI & PN
wilcox.test(df.cat.molestarPIPN$Rating ~ df.cat.molestarPIPN$Sentencetype) # = 0.004155


#MOLESTAR AA & PI
wilcox.test(df.cat.molestarAAPI$Rating ~ df.cat.molestarAAPI$Sentencetype) # = 0.09956


#MOLESTAR AI & PA
wilcox.test(df.cat.molestarAIPA$Rating ~ df.cat.molestarAIPA$Sentencetype) # = 6.043e-05

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, PI&PN, AA&PA
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AI&PI, PA&PN
  - The means differ significantly in the following pairs:                PA&PI, AA&PA, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AI&PI, PA&PN



PREOCUPAR
```{r}

#Create relevant subsets to test for animacy effects throughout PREOCUPAR (P)
df.cat.preocuparAA <- subset(df.cat.allAA, Verb == "P")
df.cat.preocuparAI <- subset(df.cat.allAI, Verb == "P")
df.cat.preocuparPA <- subset(df.cat.allPA, Verb == "P")
df.cat.preocuparPI <- subset(df.cat.allPI, Verb == "P")
df.cat.preocuparPN <- subset(df.cat.allPN, Verb == "P")

```

```{r}
#Shapiro test to test for normal distribution among the PREOCUPAR (P) subsets
shapiro.test(df.cat.preocuparAA$Rating) # = 0.0001797
shapiro.test(df.cat.preocuparAI$Rating) # = 5.994e-08
shapiro.test(df.cat.preocuparPA$Rating) # = 1.125e-08
shapiro.test(df.cat.preocuparPI$Rating) # = 2.573e-09
shapiro.test(df.cat.preocuparPN$Rating) # = 5.224e-08

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.preocuparAAAI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AA','AI'))
df.cat.preocuparPAPI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PA','PI'))
df.cat.preocuparAAPA <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AA','PA'))
df.cat.preocuparAIPI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AI','PI'))
df.cat.preocuparPAPN <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PA','PN'))
df.cat.preocuparPIPN <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('PI','PN'))
df.cat.preocuparAAPI <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AA','PI'))
df.cat.preocuparAIPA <- subset(df.cat.SD, Verb=='P' & Sentencetype %in% c('AI','PA'))



#shapiro tests for new subsets
shapiro.test(df.cat.preocuparAAAI$Rating) # = 1.582e-09
shapiro.test(df.cat.preocuparPAPI$Rating) # = 6.987e-13
shapiro.test(df.cat.preocuparAAPA$Rating) # = 6.614e-10
shapiro.test(df.cat.preocuparAIPI$Rating) # = 2.306e-12
shapiro.test(df.cat.preocuparPAPN$Rating) # = 5.567e-12
shapiro.test(df.cat.preocuparPIPN$Rating) # = 2.099e-12
shapiro.test(df.cat.preocuparAAPI$Rating) # = 4.002e-10
shapiro.test(df.cat.preocuparAIPA$Rating) # = 6.018e-12


#Levene Test to test for variance among all verbs
#PREOCUPAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI) # 0.0003589 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI, center=mean) # 0.0001116 ***


#PREOCUPAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI) # 0.6446
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI, center=mean) # 0.3541


#PREOCUPAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA) # 6.254e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA, center=mean) # 9.682e-06 ***


#PREOCUPAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI) # 0.2973
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI, center=mean) # 0.03299 *


#PREOCUPAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN) # 0.3821
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN, center=mean) # 0.05845 .


#PREOCUPAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN) # 0.2285
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN, center=mean) # 0.01163 *


#PREOCUPAR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPI) # 2.91e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPI, center=mean) # 3.142e-06 ***


#PREOCUPAR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN) # 0.2285
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN, center=mean) # 0.01163 *


```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.preocupar <- subset(df.cat.SD, Verb == "P")
tapply(df.cat.preocupar$Rating, list(df.cat.preocupar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#PREOCUPAR AA & AI
wilcox.test(df.cat.preocuparAAAI$Rating ~ df.cat.preocuparAAAI$Sentencetype) # = 0.007288


#PREOCUPAR PA &PI
wilcox.test(df.cat.preocuparPAPI$Rating ~ df.cat.preocuparPAPI$Sentencetype) # = 0.654


#PREOCUPAR AA & PA
wilcox.test(df.cat.preocuparAAPA$Rating ~ df.cat.preocuparAAPA$Sentencetype) # = 0.002354 


#PREOCUPAR AI & PI
wilcox.test(df.cat.preocuparAIPI$Rating ~ df.cat.preocuparAIPI$Sentencetype) # = 0.3769 


#PREOCUPAR PA & PN
wilcox.test(df.cat.preocuparPAPN$Rating ~ df.cat.preocuparPAPN$Sentencetype) # = 0.6221 


#PREOCUPAR PI & PN
wilcox.test(df.cat.preocuparPIPN$Rating ~ df.cat.preocuparPIPN$Sentencetype) # = 0.3573 


#PREOCUPAR AA & PI
wilcox.test(df.cat.preocuparAAPI$Rating ~ df.cat.preocuparAAPI$Sentencetype) # = 0.0009298


#PREOCUPAR AI & PA
wilcox.test(df.cat.preocuparAIPA$Rating ~ df.cat.preocuparAIPA$Sentencetype) # = 0.6595

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI, AA&PA
  - The variance does NOT differ significantly in the following pairs:    PA&PI, PA&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AI&PI, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, AA&PA
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN


SORPRENDRE
```{r}

#Create relevant subsets to test for animacy effects throughout SORPRENDRE (S)
df.cat.sorprendreAA <- subset(df.cat.allAA, Verb == "S") # empty dataset
df.cat.sorprendreAI <- subset(df.cat.allAI, Verb == "S") # double the size (7 & 90) - delete 90?
df.cat.sorprendrePA <- subset(df.cat.allPA, Verb == "S")
df.cat.sorprendrePI <- subset(df.cat.allPI, Verb == "S")
df.cat.sorprendrePN <- subset(df.cat.allPN, Verb == "S")

```

```{r}
#Shapiro test to test for normal distribution among the SORPRENDRE (S) subsets
shapiro.test(df.cat.sorprendreAA$Rating) # empty dataset
shapiro.test(df.cat.sorprendreAI$Rating) # = 2.491e-06
shapiro.test(df.cat.sorprendrePA$Rating) # = 7.28e-05
shapiro.test(df.cat.sorprendrePI$Rating) # = 0.001331
shapiro.test(df.cat.sorprendrePN$Rating) # = 7.893e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.sorprendreAAAI <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('AA','AI'))
df.cat.sorprendrePAPI <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('PA','PI'))
df.cat.sorprendreAAPA <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('AA','PA'))
df.cat.sorprendreAIPI <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('AI','PI'))
df.cat.sorprendrePAPN <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('PA','PN'))
df.cat.sorprendrePIPN <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('PI','PN'))
df.cat.sorprendreAAPI <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('AA','PI'))
df.cat.sorprendreAIPA <- subset(df.cat.SD, Verb=='S' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.sorprendreAAAI$Rating) # = 2.491e-06
shapiro.test(df.cat.sorprendrePAPI$Rating) # = 1.133e-06
shapiro.test(df.cat.sorprendreAAPA$Rating) # = 7.28e-05
shapiro.test(df.cat.sorprendreAIPI$Rating) # = 6.283e-08
shapiro.test(df.cat.sorprendrePAPN$Rating) # = 4.312e-08
shapiro.test(df.cat.sorprendrePIPN$Rating) # = 3.172e-07
shapiro.test(df.cat.sorprendreAAPI$Rating) # = 0.001331
shapiro.test(df.cat.sorprendreAIPA$Rating) # = 1.592e-08


#Levene Test to test for variance among all verbs
#SORPRENDRE verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI, center=mean) 


#SORPRENDRE verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI) # 0.8955
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI, center=mean) # 0.8833


#SORPRENDRE verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA, center=mean) 


#SORPRENDRE verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI) # 0.3406
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI, center=mean) # 0.2102


#SORPRENDRE verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN) # 0.9187
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN, center=mean) # 0.766


#SORPRENDRE verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN) # 1
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN, center=mean) # 0.6403


#SORPRENDRE verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPI) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPI, center=mean) 


#SORPRENDRE verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPA) # 0.4318
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPA, center=mean) # 0.3068

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.sorprendre <- subset(df.cat.SD, Verb == "S")
tapply(df.cat.sorprendre$Rating, list(df.cat.sorprendre$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#SORPRENDRE AA & AI
wilcox.test(df.cat.sorprendreAAAI$Rating ~ df.cat.sorprendreAAAI$Sentencetype) # Doesn't work because AA set is empty


#SORPRENDRE PA &PI
wilcox.test(df.cat.sorprendrePAPI$Rating ~ df.cat.sorprendrePAPI$Sentencetype) # = 0.5803


#SORPRENDRE AA & PA
wilcox.test(df.cat.sorprendreAAPA$Rating ~ df.cat.sorprendreAAPA$Sentencetype) # Doesn't work because AA set is empty


#SORPRENDRE AI & PI
wilcox.test(df.cat.sorprendreAIPI$Rating ~ df.cat.sorprendreAIPI$Sentencetype) # = 0.8942


#SORPRENDRE PA & PN
wilcox.test(df.cat.sorprendrePAPN$Rating ~ df.cat.sorprendrePAPN$Sentencetype) # = 0.4238 


#SORPRENDRE PI & PN
wilcox.test(df.cat.sorprendrePIPN$Rating ~ df.cat.sorprendrePIPN$Sentencetype) # = 0.2055


#SORPRENDRE PI & PN
wilcox.test(df.cat.sorprendrePIPN$Rating ~ df.cat.sorprendrePIPN$Sentencetype) # Doesn't work


#SORPRENDRE PI & PN
wilcox.test(df.cat.sorprendrePIPN$Rating ~ df.cat.sorprendrePIPN$Sentencetype) # = 0.2055

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AI&PI,PA&PN, PI&PN
  - The means differ significantly in the following pairs:                NONE
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN
  - AA&AI and AA&PA could not be tested because of missing data



ENTRISTIR
```{r}

#Create relevant subsets to test for animacy effects throughout ENTRISTIR (T)
df.cat.entristirAA <- subset(df.cat.allAA, Verb == "T")
df.cat.entristirAI <- subset(df.cat.allAI, Verb == "T")
df.cat.entristirPA <- subset(df.cat.allPA, Verb == "T")
df.cat.entristirPI <- subset(df.cat.allPI, Verb == "T")
df.cat.entristirPN <- subset(df.cat.allPN, Verb == "T")

```

```{r}
#Shapiro test to test for normal distribution among the ENTRISTIR (T) subsets
shapiro.test(df.cat.entristirAA$Rating) # = 0.001661
shapiro.test(df.cat.entristirAI$Rating) # = 0.0004177
shapiro.test(df.cat.entristirPA$Rating) # = 9.485e-07
shapiro.test(df.cat.entristirPI$Rating) # = 2.483e-08
shapiro.test(df.cat.entristirPN$Rating) # = 5.117e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.entristirAAAI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AA','AI'))
df.cat.entristirPAPI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PA','PI'))
df.cat.entristirAAPA <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AA','PA'))
df.cat.entristirAIPI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AI','PI'))
df.cat.entristirPAPN <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PA','PN'))
df.cat.entristirPIPN <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('PI','PN'))
df.cat.entristirAAPI <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AA','PI'))
df.cat.entristirAIPA <- subset(df.cat.SD, Verb=='T' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.entristirAAAI$Rating) # = 5.182e-06
shapiro.test(df.cat.entristirPAPI$Rating) # = 5.156e-11
shapiro.test(df.cat.entristirAAPA$Rating) # = 8.222e-08
shapiro.test(df.cat.entristirAIPI$Rating) # = 5.777e-09
shapiro.test(df.cat.entristirPAPN$Rating) # = 1.017e-09
shapiro.test(df.cat.entristirPIPN$Rating) # = 1.695e-10
shapiro.test(df.cat.entristirAAPI$Rating) # = 1.334e-08
shapiro.test(df.cat.entristirAIPA$Rating) # = 3.087e-08


#Levene Test to test for variance among all verbs
#ENTRISTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI) # 0.7815
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI, center=mean) # 0.9551


#ENTRISTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPI) # 0.4692
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPI, center=mean) # 0.3266


#ENTRISTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA) # 0.005135 **
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA, center=mean) # 0.001201 **


#ENTRISTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI) # 0.003919 **
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI, center=mean) # 0.0001639 ***


#ENTRISTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN) # 0.1371
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN, center=mean) # 0.01415 *


#ENTRISTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN) # 0.0501 .
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN, center=mean) # 0.002344 **


#ENTRISTIR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPI) # 0.0006439 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPI, center=mean) # 0.0001183 ***


#ENTRISTIR verbs AI & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPA) # 0.02033 *
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPA, center=mean) # 0.001487 **

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.entristir <- subset(df.cat.SD, Verb == "T")
tapply(df.cat.entristir$Rating, list(df.cat.entristir$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups

#ENTRISTIR AA & AI
wilcox.test(df.cat.entristirAAAI$Rating ~ df.cat.entristirAAAI$Sentencetype) # = 0.991


#ENTRISTIR PA &PI
wilcox.test(df.cat.entristirPAPI$Rating ~ df.cat.entristirPAPI$Sentencetype) # = 0.3315 


#ENTRISTIR AA & PA
wilcox.test(df.cat.entristirAAPA$Rating ~ df.cat.entristirAAPA$Sentencetype) # = 0.01466


#ENTRISTIR AI & PI
wilcox.test(df.cat.entristirAIPI$Rating ~ df.cat.entristirAIPI$Sentencetype) # = 0.001073


#ENTRISTIR PA & PN
wilcox.test(df.cat.entristirPAPN$Rating ~ df.cat.entristirPAPN$Sentencetype) # = 0.2678


#All verbs PI & PN
wilcox.test(df.cat.entristirPIPN$Rating ~ df.cat.entristirPIPN$Sentencetype) # = 0.04854


#All verbs AA & PI
wilcox.test(df.cat.entristirAAPI$Rating ~ df.cat.entristirAAPI$Sentencetype) # = 0.001706


#All verbs AI & PA
wilcox.test(df.cat.entristirAIPA$Rating ~ df.cat.entristirAIPA$Sentencetype) # = 0.001706

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&PA, AI&PI; PI&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PN
  - The means differ significantly in the following pairs:                AA&PA, AI&PI, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, PA&PI, PA&PN



ESTRANYAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESTRANYAR (U)
df.cat.estranyarAA <- subset(df.cat.allAA, Verb == "U")
df.cat.estranyarAI <- subset(df.cat.allAI, Verb == "U")
df.cat.estranyarPA <- subset(df.cat.allPA, Verb == "U")
df.cat.estranyarPI <- subset(df.cat.allPI, Verb == "U")
df.cat.estranyarPN <- subset(df.cat.allPN, Verb == "U")

```

```{r}
#Shapiro test to test for normal distribution among the ESTRANYAR (U) subsets
shapiro.test(df.cat.estranyarAA$Rating) # = 0.005641
shapiro.test(df.cat.estranyarAI$Rating) # = 0.003165
shapiro.test(df.cat.estranyarPA$Rating) # = 0.03248
shapiro.test(df.cat.estranyarPI$Rating) # = 1.054e-05
shapiro.test(df.cat.estranyarPN$Rating) # = 4.941e-07

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.estranyarAAAI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AA','AI'))
df.cat.estranyarPAPI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PA','PI'))
df.cat.estranyarAAPA <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AA','PA'))
df.cat.estranyarAIPI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AI','PI'))
df.cat.estranyarPAPN <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PA','PN'))
df.cat.estranyarPIPN <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('PI','PN'))
df.cat.estranyarAAPI <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AA','PI'))
df.cat.estranyarAIPA <- subset(df.cat.SD, Verb=='U' & Sentencetype %in% c('AI','PA'))


#shapiro tests for new subsets
shapiro.test(df.cat.estranyarAAAI$Rating) # = 0.0001484
shapiro.test(df.cat.estranyarPAPI$Rating) # = 1.044e-05
shapiro.test(df.cat.estranyarAAPA$Rating) # = 0.0003659
shapiro.test(df.cat.estranyarAIPI$Rating) # = 2.212e-05
shapiro.test(df.cat.estranyarPAPN$Rating) # = 8.933e-07
shapiro.test(df.cat.estranyarPIPN$Rating) # = 1.058e-09
shapiro.test(df.cat.estranyarAAPI$Rating) # = 2.365e-06
shapiro.test(df.cat.estranyarAIPA$Rating) # = 0.0006548


#Levene Test to test for variance among all verbs
#ESTRANYAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI) # 0.01956 *
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI, center=mean) # 0.006063 **


#ESTRANYAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI) # 0.1177
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI, center=mean) # 0.08049 .


#ESTRANYAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA) # 0.5165
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA, center=mean) # 0.4261


#ESTRANYAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI) # 0.9227
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI, center=mean) # 0.834


#ESTRANYAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN) # 4.057e-06 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN, center=mean) # 2.804e-06 ***


#ESTRANYAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN) # 0.06319 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN, center=mean) # 0.01152 *


#ESTRANYAR verbs AA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPI) # 0.05282 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPI, center=mean) # 0.01697 *


#ESTRANYAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN) # 0.06319 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN, center=mean) # 0.01152 *

```

```{r}
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

df.cat.estranyar <- subset(df.cat.SD, Verb == "U")
tapply(df.cat.estranyar$Rating, list(df.cat.estranyar$Sentencetype), mean, na.rm=TRUE)

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there's a significant difference between the two groups

#ESTARNYAR AA & AI
wilcox.test(df.cat.estranyarAAAI$Rating ~ df.cat.estranyarAAAI$Sentencetype) # = 0.01743


#ESTRANYAR PA &PI
wilcox.test(df.cat.estranyarPAPI$Rating ~ df.cat.estranyarPAPI$Sentencetype) # = 0.002848


#ESTRANYAR AA & PA
wilcox.test(df.cat.estranyarAAPA$Rating ~ df.cat.estranyarAAPA$Sentencetype) # = 0.7053


#ESTRANYAR AI & PI
wilcox.test(df.cat.estranyarAIPI$Rating ~ df.cat.estranyarAIPI$Sentencetype) # = 3.938e-06


#ESTRANYAR PA & PN
wilcox.test(df.cat.estranyarPAPN$Rating ~ df.cat.estranyarPAPN$Sentencetype) # = 9.379e-06


#ESTRANYAR PI & PN
wilcox.test(df.cat.estranyarPIPN$Rating ~ df.cat.estranyarPIPN$Sentencetype) # = 0.09934


#ESTRANYAR AA & PI
wilcox.test(df.cat.estranyarAAPI$Rating ~ df.cat.estranyarAAPI$Sentencetype) # = 0.0272


#ESTRANYAR AI & PA
wilcox.test(df.cat.estranyarAIPA$Rating ~ df.cat.estranyarAIPA$Sentencetype) # = 0.01499

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AA&PA, AI&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PI&PN
  - The means differ significantly in the following pairs:                AA&AI, PA&PI, AI&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&PA, PI&PN