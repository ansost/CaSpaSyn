---
title: '"Acceptabiliy Analysis for Catalan and Spanish Ratings"'
author: "ASSASSMG"
date: "`r Sys.Date()`"
output: html_document
---

```{r, setup, include=FALSE}
# The following line sets the [working directory](https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html) for reading in the files. 
# Exchange the part before `/CaSpaSyn/code` with wherever you have the copy of the repository.
knitr::opts_knit$set(root.dir = "~/repos/CaSpaSyn/code/")

# Don't include warnings and messages in the rendered document.
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r packages, include=FALSE}
# Load/install libraries. 
#install.packages("tidyverse")
packages <- c("tidyverse", "lubridate", "gridExtra", "car", "namer")

installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
	install.packages(packages[!installed_packages])
}

invisible(lapply(packages, library, character.only = TRUE))
```

# Data Exploration

```{r loadData}
# Load data.
df.cat.initial <- read_csv("../data/Catalan_ASSASSMG.csv")
df.spa.initial <- read_csv("../data/Spanish_ASSASSMG.csv")

# Print data overview.
str(df.cat.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
str(df.spa.initial, give.attr = FALSE, give.length = FALSE, vec.len = 3, max.level = 3, digits.d = 3)
```

```{r dataTreatment, include = FALSE}
# Make sure that the ratings are treated as numerical data, not strings. 
df.cat <- transform(df.cat.initial, Rating = as.numeric(Rating))
df.spa <- transform(df.spa.initial, Rating = as.numeric(Rating))
```

## Overall Rating Distribution

Ratings are very skewed towards the high end of the scale.

```{r ratingBoxplot, echo=FALSE}
box.spa <- ggplot(df.spa, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) + # display all x axis ticks
    ggtitle("Castilian Ratings")

box.cat <- ggplot(df.cat, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) + # display all x axis ticks 
    ggtitle("Catalan Ratings")

grid.arrange(box.spa, box.cat, ncol=2)
#ggsave(filename = "../figures/rating_count_distribution.png")
```

```{r normalityAllRatings, echo=FALSE}
shapiro.test(df.cat$Rating)
shapiro.test(df.spa$Rating)
```

## Outlier Inspection

### Participants

Plots of rating distribution per participant.

#### Catalan

```{r catRatingDist, figures-side, fig.show="hold", out.width="50%", echo = FALSE}
for (i in c(unique(df.cat$Code))) {
  subset(df.cat, Code %in% c(unique(df.cat$Code)))
  temp <- subset(df.cat, Code == i)

  name <- paste("Rating distribution of participant", i, sep = " ")
  
  print(ggplot(temp, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) + # display all x axis ticks 
    ggtitle(name))
  
  temp <- transform(temp, Rating = as.numeric(Rating))
}
```

#### Castilian

```{r spaRatingDist, fig.show="hold", out.width="50%", echo = FALSE}
for (i in c(unique(df.spa$Code))) {
  subset(df.cat, Code %in% c(unique(df.spa$Code)))
  temp <- subset(df.spa, Code == i)

  name <- paste("Rating distribution of participant", i, sep = " ")
  
  print(ggplot(temp, aes(x=Rating)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=7) +# display all x axis ticks 
    ggtitle(name))
}
```

### Survey Completion Time

Check for completion times 1 standard deviation away from average survey completion time ([source](https://academic.oup.com/poq/article/72/5/914/1832496#28138951)).

```{r surveytime, results = "hide", echo = FALSE}
# Make new column with duration in minutes for Catalan and Castilian
df.cat <- df.cat %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))
df.spa <- df.spa %>%
mutate(surveyduration = minute(seconds_to_period(End - Start)))

# Subset df for participants
subjTimes.cat <- df.cat %>% distinct(Code, .keep_all = T) 
subjTimes.spa <- df.spa %>% distinct(Code, .keep_all = T) 

# Plot
times.cat <- ggplot(subjTimes.cat, aes(x=surveyduration)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=23) +# display all x axis ticks 
    ggtitle("Survey durations Catalan")

times.spa <- ggplot(subjTimes.spa, aes(x=surveyduration)) +
    geom_histogram(binwidth=.5, na.rm = TRUE,
                   colour="black", fill="white") + 
    scale_x_continuous(n.breaks=23) +# display all x axis ticks 
    ggtitle("Survey durations Castilian")

grid.arrange(times.spa, times.cat, ncol=2)
#ggsave(filename = "../figures/surveydurations.png")

# Find exclusion criteria, usually 1 SD away from the mean, 1.5 sd in brackets
round(mean(df.cat$surveyduration) + 1.5 *sd(df.cat$surveyduration), 0) # 17 (19)
round(mean(df.cat$surveyduration) - 1.5 *sd(df.cat$surveyduration), 0) # 10 (8)

round(mean(df.spa$surveyduration) + 1.5 *sd(df.spa$surveyduration), 0) # 19 (21)
round(mean(df.spa$surveyduration) - 1.5 *sd(df.spa$surveyduration), 0) # 8 (6)
```

The strong filter (1 SD from the mean) would exclude over half of the participants, the lax filter (1.5 SD from the mean) much less. 

```{r exclusionTimes, results="hide"}
nrow(subjTimes.cat %>% filter(surveyduration < 10 | surveyduration > 17)) # 14 out of 25
nrow(subjTimes.cat %>% filter(surveyduration < 8 | surveyduration > 19)) # 2 out of 25

nrow(subjTimes.spa %>% filter(surveyduration < 8 | surveyduration > 9)) # 21 out of 26
nrow(subjTimes.spa %>% filter(surveyduration < 6 | surveyduration > 21)) # 3 out of 26
```


### Rating Development over Time

Check whether participants used more extreme ratings towards the end of the study. Split (experimental) items in two groups: 50%:50% and 45%:15% and compare rating distribution. Extreme deviation from the rest of the split may lead to exclusion fo the participants.

```{r}
# code here
```

# Comparing Castilian and Catalan verbs in regards to dativ usage

Test for normal distribution of the ratings using the Shapiro-Wilk normality test (comes with base R).

```{r}
# shapiro.test(df$COLUMNNAME)
```

Use non-parametric tests after we show that most of the data is not normally distributed For a given verb, compare the active and pronominal usage using: - **variance** of the ratings with the Levene test - **means** of the ratings using man Mann-Whitney test

Compare the Variance.

```{r}
#leveneTest(abhängige Variable ~ Gruppierungsvariable, data = df)
```

Compare the Means. (Heißt Wilcox, mach aber Mann-Whitney) If the p-value is below 0.05 there is a significat difference between the two groups. The function `tapply` prints the mean of the two groups, which is not done by the `wilcox` function.

```{r}
#wilcox.test(df$abhängige Variable ~ df$Gruppierungsvariable)
#tapply(df$group1,df$group2,mean)
```

# Comparison between Castilian and Catalan Cognates

AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA oder PI)

...same as above once the code works.

```{r}
# code here
```

# Animacy Comparison

For the category "all verbs", as well as each individual verb (encantar, divertir, molestar, espantar,...), you will find the following code-blocks:

1. Create relevant subsets for Shapiro Test to test for normal distribution
2. Shapiro Tests for subsets created in 1.
3. New subsets to compare the relevant animacy properties; Shapiro Tests conducted with those subsets (not sure if that was necessary, but bettr safe than sorry), Levene Test
4. Mann-Whitney U Test & means output via tapply
5. First comments

A note on the Levene Test: 
Depending on whether the median or the mean is used as center, the resulting numbers differs by quite a lot.


**ALL VERBS**

```{r}

#Create relevant subsets to test for animacy effects throughout all verbs
df.cat.allAA <- subset(df.cat, Sentencetype == "AA")
df.cat.allAI <- subset(df.cat, Sentencetype == "AI")
df.cat.allPA <- subset(df.cat, Sentencetype == "PA")
df.cat.allPI <- subset(df.cat, Sentencetype == "PI")
df.cat.allPN <- subset(df.cat, Sentencetype == "PN")

```

```{r}

#Shapiro Test to test for normal distribution (anything below 0.05 is not normal)
shapiro.test(df.cat$Rating)  # <2.2e-16 (not normal distribution)

#Shapiro test to test for normal distribution among the Sentencytype subsets

shapiro.test(df.cat.allAA$Rating) # = 2.832e-12 
shapiro.test(df.cat.allAI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPA$Rating) # = 1.742e-14
shapiro.test(df.cat.allPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPN$Rating) # < 2.2e-16

```

```{r}

#Levene test

library(car) #necessary for levene test to work

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.allAAAI <- subset(df.cat, Sentencetype %in% c('AA','AI'))
df.cat.allPAPI <- subset(df.cat, Sentencetype %in% c('PA','PI'))
df.cat.allAAPA <- subset(df.cat, Sentencetype %in% c('AA','PA'))
df.cat.allAIPI <- subset(df.cat, Sentencetype %in% c('AI','PI'))
df.cat.allPAPN <- subset(df.cat, Sentencetype %in% c('PA','PN'))
df.cat.allPIPN <- subset(df.cat, Sentencetype %in% c('PI','PN'))



#shapiro tests for new subsets, just in case (unsurprisingly, none are normally distributed)

shapiro.test(df.cat.allAAAI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allAAPA$Rating) # < 2.2e-16
shapiro.test(df.cat.allAIPI$Rating) # < 2.2e-16
shapiro.test(df.cat.allPAPN$Rating) # < 2.2e-16
shapiro.test(df.cat.allPIPN$Rating) # < 2.2e-16



#Levene Test to test for variance among all verbs
#"*" mark how significant the variance is
#The more "*", the more significant

#All verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI) # 0.3661
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAAI, center=mean) # 0.6011


#All verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI) # 0.0004737 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPI, center=mean) # 2.602e-05 ***


#All verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA) # 0.4171
leveneTest(Rating ~ Sentencetype, data = df.cat.allAAPA, center=mean) # 0.1175


#All verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI) # 0.02871 *
leveneTest(Rating ~ Sentencetype, data = df.cat.allAIPI, center=mean) # 0.0237 *


#All verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN) # 0.003066 **
leveneTest(Rating ~ Sentencetype, data = df.cat.allPAPN, center=mean) # 0.0003018 ***


#All verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN) # 0.6189
leveneTest(Rating ~ Sentencetype, data = df.cat.allPIPN, center=mean) # 0.4484

```

```{r}

#Mann-Whitney U test via wilcox function

#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#All verbs AA & AI
wilcox.test(df.cat.allAAAI$Rating ~ df.cat.allAAAI$Sentencetype) # = 0.0363
tapply(df.cat.allAAAI$Rating,df.cat.allAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 5.188571, AI: 5.524664 


#All verbs PA &PI
wilcox.test(df.cat.allPAPI$Rating ~ df.cat.allPAPI$Sentencetype) # = 4.006e-05
tapply(df.cat.allPAPI$Rating,df.cat.allPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 5.16, PI: 5.92 


#All verbs AA & PA
wilcox.test(df.cat.allAAPA$Rating ~ df.cat.allAAPA$Sentencetype) # = 0.7785
tapply(df.cat.allAAPA$Rating,df.cat.allAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 5.188571, PA: 5.160000 


#All verbs AI & PI
wilcox.test(df.cat.allAIPI$Rating ~ df.cat.allAIPI$Sentencetype) # = 0.008793
tapply(df.cat.allAIPI$Rating,df.cat.allAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 5.524664, PI: 5.920000 


#All verbs PA & PN
wilcox.test(df.cat.allPAPN$Rating ~ df.cat.allPAPN$Sentencetype) # = 0.6022
tapply(df.cat.allPAPN$Rating,df.cat.allPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 5.160, PN: 5.835 


#All verbs PI & PN
wilcox.test(df.cat.allPIPN$Rating ~ df.cat.allPIPN$Sentencetype) # = 0.6022
tapply(df.cat.allPIPN$Rating,df.cat.allPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 5.920, PN: 5.835 

```


Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, AI&PI, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AA&PA, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, PA&PI, AI&PI
  - The means do NOT differ significantly in the following pairs:         AA&PA, PA&PN, PI&PN





# PER VERB

#encantar (C)
#divertir (D)
#espanatr (E)
#molestar (M)
#preocupar (P)
#sorprendre (S)
#entristir (T)
#estranyar (U)


ENCANTAR
```{r}
#Create relevant subsets to test for animacy effects throughout ENCANTAR (C)
df.cat.encantarAA <- subset(df.cat.allAA, Verb == "C")
df.cat.encantarAI <- subset(df.cat.allAI, Verb == "C")
df.cat.encantarPA <- subset(df.cat.allPA, Verb == "C")
df.cat.encantarPI <- subset(df.cat.allPI, Verb == "C")
df.cat.encantarPN <- subset(df.cat.allPN, Verb == "C")

```

```{r}
#Shapiro test to test for normal distribution among the ENCANTAR (C) subsets
shapiro.test(df.cat.encantarAA$Rating) # = 0.0008615
shapiro.test(df.cat.encantarAI$Rating) # = 0.02714
shapiro.test(df.cat.encantarPA$Rating) # = 0.03196
shapiro.test(df.cat.encantarPI$Rating) # = 0.004699
shapiro.test(df.cat.encantarPN$Rating) # = 0.005067


```
 
```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.encantarAAAI <- subset(df.cat, Verb=='C' & Sentencetype %in% c('AA','AI'))
df.cat.encantarPAPI <- subset(df.cat, Verb=='C' & Sentencetype %in% c('PA','PI'))
df.cat.encantarAAPA <- subset(df.cat, Verb=='C' & Sentencetype %in% c('AA','PA'))
df.cat.encantarAIPI <- subset(df.cat, Verb=='C' & Sentencetype %in% c('AI','PI'))
df.cat.encantarPAPN <- subset(df.cat, Verb=='C' & Sentencetype %in% c('PA','PN'))
df.cat.encantarPIPN <- subset(df.cat, Verb=='C' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.encantarAAAI$Rating) # = 6.162e-05
shapiro.test(df.cat.encantarPAPI$Rating) # = 0.0002231
shapiro.test(df.cat.encantarAAPA$Rating) # = 0.0001651
shapiro.test(df.cat.encantarAIPI$Rating) # = 0.0004739
shapiro.test(df.cat.encantarPAPN$Rating) # = 0.0004242
shapiro.test(df.cat.encantarPIPN$Rating) # = 0.0002352


#Levene Test to test for variance among all verbs
#ENCANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI) # 0.2572
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAAI, center=mean) # 0.08937 .


#ENCANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI) # 0.796
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI, center=mean) # 0.8252


#ENCANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA) # 0.6349
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAAPA, center=mean) # 0.4133


#ENCANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI) # 0.2478
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarAIPI, center=mean) # 0.218


#ENCANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN) # 0.4531
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPN, center=mean) # 0.4219


#ENCANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN) # 0.5952
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPIPN, center=mean) # 0.5695



```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#ENCANTAR AA & AI
wilcox.test(df.cat.encantarAAAI$Rating ~ df.cat.encantarAAAI$Sentencetype) # = 0.752
tapply(df.cat.encantarAAAI$Rating,df.cat.encantarAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 4.80, AI: 4.84 


#ENCANTAR PA &PI
wilcox.test(df.cat.encantarPAPI$Rating ~ df.cat.encantarPAPI$Sentencetype) # = 0.5463
tapply(df.cat.encantarPAPI$Rating,df.cat.encantarPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 3.52, PI: 3.20 


#ENCANTAR AA & PA
wilcox.test(df.cat.encantarAAPA$Rating ~ df.cat.encantarAAPA$Sentencetype) # = 0.03201
tapply(df.cat.encantarAAPA$Rating,df.cat.encantarAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 4.80, PA: 3.52


#ENCANTAR AI & PI
wilcox.test(df.cat.encantarAIPI$Rating ~ df.cat.encantarAIPI$Sentencetype) # = 0.006434
tapply(df.cat.encantarAIPI$Rating,df.cat.encantarAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 4.84, PI: 3.20


#ENCANTAR PA & PN
wilcox.test(df.cat.encantarPAPN$Rating ~ df.cat.encantarPAPN$Sentencetype) # = 0.1262
tapply(df.cat.encantarPAPN$Rating,df.cat.encantarPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 3.52, PN: 4.40 


#ENCANTAR PI & PN
wilcox.test(df.cat.encantarPIPN$Rating ~ df.cat.encantarPIPN$Sentencetype) # = 0.03849
tapply(df.cat.encantarPIPN$Rating,df.cat.encantarPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 3.2, PN: 4.4 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI AA&PA, AI&PI, PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AA&PA, AI&PI, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, PA&PI, PA&PN




DIVERTIR

```{r}

#Create relevant subsets to test for animacy effects throughout DIVERTIR (D)
df.cat.divertirAA <- subset(df.cat.allAA, Verb == "D")
df.cat.divertirAI <- subset(df.cat.allAI, Verb == "D")
df.cat.divertirPA <- subset(df.cat.allPA, Verb == "D")
df.cat.divertirPI <- subset(df.cat.allPI, Verb == "D")
df.cat.divertirPN <- subset(df.cat.allPN, Verb == "D")

```

```{r}
#Shapiro test to test for normal distribution among the DIVERTIR (D) subsets
shapiro.test(df.cat.divertirAA$Rating) # = 0.002142
shapiro.test(df.cat.divertirAI$Rating) # = 1.335e-07
shapiro.test(df.cat.divertirPA$Rating) # = 5.853e-05 
shapiro.test(df.cat.divertirPI$Rating) # = 1.775e-06
shapiro.test(df.cat.divertirPN$Rating) # = 0.0001756

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.divertirAAAI <- subset(df.cat, Verb=='D' & Sentencetype %in% c('AA','AI'))
df.cat.divertirPAPI <- subset(df.cat, Verb=='D' & Sentencetype %in% c('PA','PI'))
df.cat.divertirAAPA <- subset(df.cat, Verb=='D' & Sentencetype %in% c('AA','PA'))
df.cat.divertirAIPI <- subset(df.cat, Verb=='D' & Sentencetype %in% c('AI','PI'))
df.cat.divertirPAPN <- subset(df.cat, Verb=='D' & Sentencetype %in% c('PA','PN'))
df.cat.divertirPIPN <- subset(df.cat, Verb=='D' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.divertirAAAI$Rating) # = 6.401e-08
shapiro.test(df.cat.divertirPAPI$Rating) # = 1.05e-08
shapiro.test(df.cat.divertirAAPA$Rating) # = 7.465e-06
shapiro.test(df.cat.divertirAIPI$Rating) # = 2.413e-10
shapiro.test(df.cat.divertirPAPN$Rating) # = 1.709e-07
shapiro.test(df.cat.divertirPIPN$Rating) # = 5.676e-08


#Levene Test to test for variance among all verbs
#DIVERTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI) # 2.487e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAAI, center=mean) # 2.493e-05 ***


#DIVERTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI) # 0.1055
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPI, center=mean) # 0.01902 *


#DIVERTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA) # 0.6358
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAAPA, center=mean) # 0.6757


#DIVERTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI) # 0.4563
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirAIPI, center=mean) # 0.3676


#DIVERTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN) # 0.2026
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPAPN, center=mean) # 0.01374 *


#DIVERTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN) # 0.3799
leveneTest(Rating ~ Sentencetype, data = df.cat.divertirPIPN, center=mean) # 0.8446

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#DIVERTIR AA & AI
wilcox.test(df.cat.divertirAAAI$Rating ~ df.cat.divertirAAAI$Sentencetype) # = 0.0008429
tapply(df.cat.divertirAAAI$Rating,df.cat.divertirAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 4.92, AI: 6.52 


#DIVERTIR PA &PI
wilcox.test(df.cat.divertirPAPI$Rating ~ df.cat.divertirPAPI$Sentencetype) # = 0.182
tapply(df.cat.divertirPAPI$Rating,df.cat.divertirPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 5.52, PI: 6.28 


#DIVERTIR AA & PA
wilcox.test(df.cat.divertirAAPA$Rating ~ df.cat.divertirAAPA$Sentencetype) # = 0.1884
tapply(df.cat.divertirAAPA$Rating,df.cat.divertirAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 4.92, PA: 5.52 


#DIVERTIR AI & PI
wilcox.test(df.cat.divertirAIPI$Rating ~ df.cat.divertirAIPI$Sentencetype) # = 0.3943
tapply(df.cat.divertirAIPI$Rating,df.cat.divertirAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 6.52, PI: 6.28


#DIVERTIR PA & PN
wilcox.test(df.cat.divertirPAPN$Rating ~ df.cat.divertirPAPN$Sentencetype) # = 0.6836
tapply(df.cat.divertirPAPN$Rating,df.cat.divertirPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 5.52, PN: 6.00 


#DIVERTIR PI & PN
wilcox.test(df.cat.divertirPIPN$Rating ~ df.cat.divertirPIPN$Sentencetype) # = 0.2412
tapply(df.cat.divertirPIPN$Rating,df.cat.divertirPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 6.28, PN: 6.00 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI
  - The variance does NOT differ significantly in the following pairs:    AA&PA, AI&PI, PI&PN
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PI, PA&PN
  - The means differ significantly in the following pairs:                AA&AI
  - The means do NOT differ significantly in the following pairs:         PA&PI, AA&PA, AI&PI, PA&PN, PI&PN



ESPANTAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESPANTAR (E)
df.cat.espantarAA <- subset(df.cat.allAA, Verb == "E")
df.cat.espantarAI <- subset(df.cat.allAI, Verb == "E")
df.cat.espantarPA <- subset(df.cat.allPA, Verb == "E")
df.cat.espantarPI <- subset(df.cat.allPI, Verb == "E")
df.cat.espantarPN <- subset(df.cat.allPN, Verb == "E")

```

```{r}
#Shapiro test to test for normal distribution among the ESPANTAR (E) subsets
shapiro.test(df.cat.espantarAA$Rating) # = 0.00543
shapiro.test(df.cat.espantarAI$Rating) # = 0.0001276
shapiro.test(df.cat.espantarPA$Rating) # = 0.007452
shapiro.test(df.cat.espantarPI$Rating) # = 6.219e-06
shapiro.test(df.cat.espantarPN$Rating) # = 3.797e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.espantarAAAI <- subset(df.cat, Verb=='E' & Sentencetype %in% c('AA','AI'))
df.cat.espantarPAPI <- subset(df.cat, Verb=='E' & Sentencetype %in% c('PA','PI'))
df.cat.espantarAAPA <- subset(df.cat, Verb=='E' & Sentencetype %in% c('AA','PA'))
df.cat.espantarAIPI <- subset(df.cat, Verb=='E' & Sentencetype %in% c('AI','PI'))
df.cat.espantarPAPN <- subset(df.cat, Verb=='E' & Sentencetype %in% c('PA','PN'))
df.cat.espantarPIPN <- subset(df.cat, Verb=='E' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.espantarAAAI$Rating) # = 6.374e-06
shapiro.test(df.cat.espantarPAPI$Rating) # = 9.149e-07
shapiro.test(df.cat.espantarAAPA$Rating) # = 8.231e-05
shapiro.test(df.cat.espantarAIPI$Rating) # = 4.328e-08
shapiro.test(df.cat.espantarPAPN$Rating) # = 1.821e-07
shapiro.test(df.cat.espantarPIPN$Rating) # = 2.448e-09


#Levene Test to test for variance among all verbs
#ESPANTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI) # 0.9908
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAAI, center=mean) # 0.9547


#ESPANTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI) # 0.006599 **
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPI, center=mean) # 0.000425 ***


#ESPANTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA) # 0.03133 *
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAAPA, center=mean) # 0.005659 **


#ESPANTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI) # 0.384 
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarAIPI, center=mean) # 0.352


#ESPANTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN) # 3.28e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPAPN, center=mean) # 3.969e-07 ***


#ESPANTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN) # 0.2547
leveneTest(Rating ~ Sentencetype, data = df.cat.espantarPIPN, center=mean) # 0.09823 . 

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#ESPANTAR AA & AI
wilcox.test(df.cat.espantarAAAI$Rating ~ df.cat.espantarAAAI$Sentencetype) # = 0.1545
tapply(df.cat.espantarAAAI$Rating,df.cat.espantarAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 5.440000, AI: 5.916667


#ESPANTAR PA &PI
wilcox.test(df.cat.espantarPAPI$Rating ~ df.cat.espantarPAPI$Sentencetype) # = 0.004237
tapply(df.cat.espantarPAPI$Rating,df.cat.espantarPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 4.6, PI: 6.2 


#ESPANTAR AA & PA
wilcox.test(df.cat.espantarAAPA$Rating ~ df.cat.espantarAAPA$Sentencetype) # = 0.2414
tapply(df.cat.espantarAAPA$Rating,df.cat.espantarAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 5.44, PA: 4.60 


#ESPANTAR AI & PI
wilcox.test(df.cat.espantarAIPI$Rating ~ df.cat.espantarAIPI$Sentencetype) # = 0.5188
tapply(df.cat.espantarAIPI$Rating,df.cat.espantarAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 5.916667, PI: 6.200000 


#ESPANTAR PA & PN
wilcox.test(df.cat.espantarPAPN$Rating ~ df.cat.espantarPAPN$Sentencetype) # = 0.0003754
tapply(df.cat.espantarPAPN$Rating,df.cat.espantarPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 4.60, PN: 6.52 


#ESPANTAR PI & PN
wilcox.test(df.cat.espantarPIPN$Rating ~ df.cat.espantarPIPN$Sentencetype) # = 0.4195 
tapply(df.cat.espantarPIPN$Rating,df.cat.espantarPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 6.20, PN: 6.52 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, AA&PA, PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AI&PI, PI&PN
  - The means differ significantly in the following pairs:                PA&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AA&PA, AI&PI, PI&PN




MOLESTAR
```{r}

#Create relevant subsets to test for animacy effects throughout MOLESTAR (M)
df.cat.molestarAA <- subset(df.cat.allAA, Verb == "M")
df.cat.molestarAI <- subset(df.cat.allAI, Verb == "M")
df.cat.molestarPA <- subset(df.cat.allPA, Verb == "M")
df.cat.molestarPI <- subset(df.cat.allPI, Verb == "M")
df.cat.molestarPN <- subset(df.cat.allPN, Verb == "M")

```

```{r}
#Shapiro test to test for normal distribution among the MOLESTAR (M) subsets
shapiro.test(df.cat.molestarAA$Rating) # = 9.95e-05
shapiro.test(df.cat.molestarAI$Rating) # = 3.94e-05
shapiro.test(df.cat.molestarPA$Rating) # = 0.03381
shapiro.test(df.cat.molestarPI$Rating) # = 2.19e-07
shapiro.test(df.cat.molestarPN$Rating) # = 0.006091

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.molestarAAAI <- subset(df.cat, Verb=='M' & Sentencetype %in% c('AA','AI'))
df.cat.molestarPAPI <- subset(df.cat, Verb=='M' & Sentencetype %in% c('PA','PI'))
df.cat.molestarAAPA <- subset(df.cat, Verb=='M' & Sentencetype %in% c('AA','PA'))
df.cat.molestarAIPI <- subset(df.cat, Verb=='M' & Sentencetype %in% c('AI','PI'))
df.cat.molestarPAPN <- subset(df.cat, Verb=='M' & Sentencetype %in% c('PA','PN'))
df.cat.molestarPIPN <- subset(df.cat, Verb=='M' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.molestarAAAI$Rating) # = 8.932e-08
shapiro.test(df.cat.molestarPAPI$Rating) # = 1.048e-06
shapiro.test(df.cat.molestarAAPA$Rating) # = 3.213e-05
shapiro.test(df.cat.molestarAIPI$Rating) # = 1.666e-09
shapiro.test(df.cat.molestarPAPN$Rating) # = 0.0004113
shapiro.test(df.cat.molestarPIPN$Rating) # = 1.608e-07


#Levene Test to test for variance among all verbs
#MOLESTAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI) # 0.1717
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAAI, center=mean) # 0.1225


#MOLESTAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI) # 0.0009811 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPI, center=mean) # 0.001633 **


#MOLESTAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA) # 0.01773 *
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAAPA, center=mean) # 0.01668 *


#MOLESTAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI) # 0.7935
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarAIPI, center=mean) # 0.5976


#MOLESTAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN) # 0.8061
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPAPN, center=mean) # 0.7582


#MOLESTAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN) # 0.001299 **
leveneTest(Rating ~ Sentencetype, data = df.cat.molestarPIPN, center=mean) # 0.0009049 ***

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#MOLESTAR AA & AI
wilcox.test(df.cat.molestarAAAI$Rating ~ df.cat.molestarAAAI$Sentencetype) # = 0.4219
tapply(df.cat.molestarAAAI$Rating,df.cat.molestarAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 5.92, AI: 6.32


#MOLESTAR PA &PI
wilcox.test(df.cat.molestarPAPI$Rating ~ df.cat.molestarPAPI$Sentencetype) # = 5.008e-05
tapply(df.cat.molestarPAPI$Rating,df.cat.molestarPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 4.12, PI: 6.40 


#MOLESTAR AA & PA
wilcox.test(df.cat.molestarAAPA$Rating ~ df.cat.molestarAAPA$Sentencetype) # = 0.001721
tapply(df.cat.molestarAAPA$Rating,df.cat.molestarAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 5.92, PA: 4.12 


#MOLESTAR AI & PI
wilcox.test(df.cat.molestarAIPI$Rating ~ df.cat.molestarAIPI$Sentencetype) # = 0.3461
tapply(df.cat.molestarAIPI$Rating,df.cat.molestarAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 6.32, PI: 6.40


#MOLESTAR PA & PN
wilcox.test(df.cat.molestarPAPN$Rating ~ df.cat.molestarPAPN$Sentencetype) # = 0.4078
tapply(df.cat.molestarPAPN$Rating,df.cat.molestarPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 4.12, PN: 4.60 


#MOLESTAR PI & PN
wilcox.test(df.cat.molestarPIPN$Rating ~ df.cat.molestarPIPN$Sentencetype) # = 0.001144
tapply(df.cat.molestarPIPN$Rating,df.cat.molestarPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 6.4, PN: 4.6 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PI, AA&PA, PI&PN
  - The variance does NOT differ significantly in the following pairs:    AA&AI, AI&PI, PA&PN                       
  - The means differ significantly in the following pairs:                PA&PI, AA&PA, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&AI, AI&PI, PA&PN



PREOCUPAR
```{r}

#Create relevant subsets to test for animacy effects throughout PREOCUPAR (P)
df.cat.preocuparAA <- subset(df.cat.allAA, Verb == "P")
df.cat.preocuparAI <- subset(df.cat.allAI, Verb == "P")
df.cat.preocuparPA <- subset(df.cat.allPA, Verb == "P")
df.cat.preocuparPI <- subset(df.cat.allPI, Verb == "P")
df.cat.preocuparPN <- subset(df.cat.allPN, Verb == "P")

```

```{r}
#Shapiro test to test for normal distribution among the PREOCUPAR (P) subsets
shapiro.test(df.cat.preocuparAA$Rating) # = 0.0001843
shapiro.test(df.cat.preocuparAI$Rating) # = 1.593e-08
shapiro.test(df.cat.preocuparPA$Rating) # = 1.109e-08
shapiro.test(df.cat.preocuparPI$Rating) # = 3.216e-09
shapiro.test(df.cat.preocuparPN$Rating) # = 1.403e-08

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.preocuparAAAI <- subset(df.cat, Verb=='P' & Sentencetype %in% c('AA','AI'))
df.cat.preocuparPAPI <- subset(df.cat, Verb=='P' & Sentencetype %in% c('PA','PI'))
df.cat.preocuparAAPA <- subset(df.cat, Verb=='P' & Sentencetype %in% c('AA','PA'))
df.cat.preocuparAIPI <- subset(df.cat, Verb=='P' & Sentencetype %in% c('AI','PI'))
df.cat.preocuparPAPN <- subset(df.cat, Verb=='P' & Sentencetype %in% c('PA','PN'))
df.cat.preocuparPIPN <- subset(df.cat, Verb=='P' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.preocuparAAAI$Rating) # = 8.178e-10
shapiro.test(df.cat.preocuparPAPI$Rating) # = 7.299e-13
shapiro.test(df.cat.preocuparAAPA$Rating) # = 5.709e-10
shapiro.test(df.cat.preocuparAIPI$Rating) # = 1.031e-12
shapiro.test(df.cat.preocuparPAPN$Rating) # = 2.346e-12
shapiro.test(df.cat.preocuparPIPN$Rating) # = 9.497e-13


#Levene Test to test for variance among all verbs
#PREOCUPAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI) # 0.0002517 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAAI, center=mean) # 7.182e-05 ***


#PREOCUPAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI) # 0.6909
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPI, center=mean) # 0.4253


#PREOCUPAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA) # 8.819e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAAPA, center=mean) # 1.471e-05 *** 


#PREOCUPAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI) # 0.5082
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparAIPI, center=mean) # 0.1651


#PREOCUPAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN) # 0.573
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPAPN, center=mean) # 0.187


#PREOCUPAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN) # 0.3842
leveneTest(Rating ~ Sentencetype, data = df.cat.preocuparPIPN, center=mean) # 0.06124 .

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#PREOCUPAR AA & AI
wilcox.test(df.cat.preocuparAAAI$Rating ~ df.cat.preocuparAAAI$Sentencetype) # = 0.001822
tapply(df.cat.preocuparAAAI$Rating,df.cat.preocuparAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 5.72, AI: 6.80


#PREOCUPAR PA &PI
wilcox.test(df.cat.preocuparPAPI$Rating ~ df.cat.preocuparPAPI$Sentencetype) # = 0.6985
tapply(df.cat.preocuparPAPI$Rating,df.cat.preocuparPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 6.84, PI:  6.88


#PREOCUPAR AA & PA
wilcox.test(df.cat.preocuparAAPA$Rating ~ df.cat.preocuparAAPA$Sentencetype) # = 0.001224
tapply(df.cat.preocuparAAPA$Rating,df.cat.preocuparAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 5.72, PA:  6.84 


#PREOCUPAR AI & PI
wilcox.test(df.cat.preocuparAIPI$Rating ~ df.cat.preocuparAIPI$Sentencetype) # = 0.6635
tapply(df.cat.preocuparAIPI$Rating,df.cat.preocuparAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 6.80, PI:  6.88 


#PREOCUPAR PA & PN
wilcox.test(df.cat.preocuparPAPN$Rating ~ df.cat.preocuparPAPN$Sentencetype) # = 0.9151
tapply(df.cat.preocuparPAPN$Rating,df.cat.preocuparPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 6.84, PN:  6.76 


#PREOCUPAR PI & PN
wilcox.test(df.cat.preocuparPIPN$Rating ~ df.cat.preocuparPIPN$Sentencetype) # = 0.6291
tapply(df.cat.preocuparPIPN$Rating,df.cat.preocuparPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 6.88, PN:  6.76 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&AI, AA&PA
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AI&PI, PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, AA&PA
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN


SORPRENDRE
```{r}

#Create relevant subsets to test for animacy effects throughout SORPRENDRE (S)
df.cat.sorprendreAA <- subset(df.cat.allAA, Verb == "S") # empty dataset
df.cat.sorprendreAI <- subset(df.cat.allAI, Verb == "S") # double the size (7 & 90) - delete 90?
df.cat.sorprendrePA <- subset(df.cat.allPA, Verb == "S")
df.cat.sorprendrePI <- subset(df.cat.allPI, Verb == "S")
df.cat.sorprendrePN <- subset(df.cat.allPN, Verb == "S")

```

```{r}
#Shapiro test to test for normal distribution among the SORPRENDRE (S) subsets
shapiro.test(df.cat.sorprendreAA$Rating) # empty dataset
shapiro.test(df.cat.sorprendreAI$Rating) # = 1.805e-06
shapiro.test(df.cat.sorprendrePA$Rating) # = 5.524e-05
shapiro.test(df.cat.sorprendrePI$Rating) # = 0.0003345
shapiro.test(df.cat.sorprendrePN$Rating) # = 1.845e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.sorprendreAAAI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AA','AI'))
df.cat.sorprendrePAPI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PA','PI'))
df.cat.sorprendreAAPA <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AA','PA'))
df.cat.sorprendreAIPI <- subset(df.cat, Verb=='S' & Sentencetype %in% c('AI','PI'))
df.cat.sorprendrePAPN <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PA','PN'))
df.cat.sorprendrePIPN <- subset(df.cat, Verb=='S' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.sorprendreAAAI$Rating) # = 1.805e-06
shapiro.test(df.cat.sorprendrePAPI$Rating) # = 3.322e-07
shapiro.test(df.cat.sorprendreAAPA$Rating) # = 5.524e-05
shapiro.test(df.cat.sorprendreAIPI$Rating) # = 1.999e-08
shapiro.test(df.cat.sorprendrePAPN$Rating) # = 1.261e-08
shapiro.test(df.cat.sorprendrePIPN$Rating) # = 4.039e-08


#Levene Test to test for variance among all verbs
#SORPRENDRE verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAAI, center=mean) 


#SORPRENDRE verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI) # 0.8953
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPI, center=mean) # 0.8768


#SORPRENDRE verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA) # Doesn't work because AA set is empty
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAAPA, center=mean) 


#SORPRENDRE verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI) # 0.3832
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendreAIPI, center=mean) # 0.2514


#SORPRENDRE verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN) # 0.7616
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePAPN, center=mean) # 0.8326


#SORPRENDRE verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN) # 0.8353
leveneTest(Rating ~ Sentencetype, data = df.cat.sorprendrePIPN, center=mean) # 0.7072

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#SORPRENDRE AA & AI
wilcox.test(df.cat.sorprendreAAAI$Rating ~ df.cat.sorprendreAAAI$Sentencetype) # Doesn't work because AA set is empty
tapply(df.cat.sorprendreAAAI$Rating,df.cat.sorprendreAAAI$Sentencetype,mean,na.rm = TRUE)  


#SORPRENDRE PA &PI
wilcox.test(df.cat.sorprendrePAPI$Rating ~ df.cat.sorprendrePAPI$Sentencetype) # = 0.8062
tapply(df.cat.sorprendrePAPI$Rating,df.cat.sorprendrePAPI$Sentencetype,mean,na.rm = TRUE) # PA: 5.80, PI: 5.76 


#SORPRENDRE AA & PA
wilcox.test(df.cat.sorprendreAAPA$Rating ~ df.cat.sorprendreAAPA$Sentencetype) # Doesn't work because AA set is empty
tapply(df.cat.sorprendreAAPA$Rating,df.cat.sorprendreAAPA$Sentencetype,mean,na.rm = TRUE)  


#SORPRENDRE AI & PI
wilcox.test(df.cat.sorprendreAIPI$Rating ~ df.cat.sorprendreAIPI$Sentencetype) # = 0.8003
tapply(df.cat.sorprendreAIPI$Rating,df.cat.sorprendreAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 5.56, PI: 5.76 


#SORPRENDRE PA & PN
wilcox.test(df.cat.sorprendrePAPN$Rating ~ df.cat.sorprendrePAPN$Sentencetype) # = 0.2927
tapply(df.cat.sorprendrePAPN$Rating,df.cat.sorprendrePAPN$Sentencetype,mean,na.rm = TRUE) # PA: 5.80, PN: 6.04 


#SORPRENDRE PI & PN
wilcox.test(df.cat.sorprendrePIPN$Rating ~ df.cat.sorprendrePIPN$Sentencetype) # = 0.2066
tapply(df.cat.sorprendrePIPN$Rating,df.cat.sorprendrePIPN$Sentencetype,mean,na.rm = TRUE) # PI: 5.76, PN: 6.04 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            NONE
  - The variance does NOT differ significantly in the following pairs:    PA&PI, AI&PI,PA&PN, PI&PN
  - The means differ significantly in the following pairs:                NONE
  - The means do NOT differ significantly in the following pairs:         PA&PI, AI&PI, PA&PN, PI&PN
  - AA&AI and AA&PA could not be tested because of missing data



ENTRISTIR
```{r}

#Create relevant subsets to test for animacy effects throughout ENTRISTIR (T)
df.cat.entristirAA <- subset(df.cat.allAA, Verb == "T")
df.cat.entristirAI <- subset(df.cat.allAI, Verb == "T")
df.cat.entristirPA <- subset(df.cat.allPA, Verb == "T")
df.cat.entristirPI <- subset(df.cat.allPI, Verb == "T")
df.cat.entristirPN <- subset(df.cat.allPN, Verb == "T")

```

```{r}
#Shapiro test to test for normal distribution among the ENTRISTIR (T) subsets
shapiro.test(df.cat.entristirAA$Rating) # = 0.002605
shapiro.test(df.cat.entristirAI$Rating) # = 0.0001039
shapiro.test(df.cat.entristirPA$Rating) # = 2.323e-07
shapiro.test(df.cat.entristirPI$Rating) # = 6.673e-09
shapiro.test(df.cat.entristirPN$Rating) # = 1.26e-06

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.entristirAAAI <- subset(df.cat, Verb=='T' & Sentencetype %in% c('AA','AI'))
df.cat.entristirPAPI <- subset(df.cat, Verb=='T' & Sentencetype %in% c('PA','PI'))
df.cat.entristirAAPA <- subset(df.cat, Verb=='T' & Sentencetype %in% c('AA','PA'))
df.cat.entristirAIPI <- subset(df.cat, Verb=='T' & Sentencetype %in% c('AI','PI'))
df.cat.entristirPAPN <- subset(df.cat, Verb=='T' & Sentencetype %in% c('PA','PN'))
df.cat.entristirPIPN <- subset(df.cat, Verb=='T' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.entristirAAAI$Rating) # = 2.644e-06
shapiro.test(df.cat.entristirPAPI$Rating) # = 8.135e-12
shapiro.test(df.cat.entristirAAPA$Rating) # = 5.131e-08
shapiro.test(df.cat.entristirAIPI$Rating) # = 7.983e-10
shapiro.test(df.cat.entristirPAPN$Rating) # = 1.489e-10
shapiro.test(df.cat.entristirPIPN$Rating) # = 2.594e-11


#Levene Test to test for variance among all verbs
#ENTRISTIR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI) # 0.7606
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAAI, center=mean) # 0.8053


#ENTRISTIR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPI) # 0.4721
leveneTest(Rating ~ Sentencetype, data = df.cat.encantarPAPI, center=mean) # 0.8252


#ENTRISTIR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA) # 0.0006153 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAAPA, center=mean) # 0.001439 **


#ENTRISTIR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI) # 0.002098 **
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirAIPI, center=mean) # 7.906e-05 ***


#ENTRISTIR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN) # 0.1416
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPAPN, center=mean) # 0.01493 *


#ENTRISTIR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN) # 0.05241 .
leveneTest(Rating ~ Sentencetype, data = df.cat.entristirPIPN, center=mean) # 0.002228 **

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there'S a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#ENTRISTIR AA & AI
wilcox.test(df.cat.entristirAAAI$Rating ~ df.cat.entristirAAAI$Sentencetype) # = 0.6089
tapply(df.cat.entristirAAAI$Rating,df.cat.entristirAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 5.04, AI: 5.28


#ENTRISTIR PA &PI
wilcox.test(df.cat.entristirPAPI$Rating ~ df.cat.entristirPAPI$Sentencetype) # = 0.3345 
tapply(df.cat.entristirPAPI$Rating,df.cat.entristirPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 6.48, PI: 6.68 


#ENTRISTIR AA & PA
wilcox.test(df.cat.entristirAAPA$Rating ~ df.cat.entristirAAPA$Sentencetype) # = 0.003812
tapply(df.cat.entristirAAPA$Rating,df.cat.entristirAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 5.04, PA: 6.48


#ENTRISTIR AI & PI
wilcox.test(df.cat.entristirAIPI$Rating ~ df.cat.entristirAIPI$Sentencetype) # = 0.001377
tapply(df.cat.entristirAIPI$Rating,df.cat.entristirAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 5.28, PI: 6.68 


#ENTRISTIR PA & PN
wilcox.test(df.cat.entristirPAPN$Rating ~ df.cat.entristirPAPN$Sentencetype) # = 0.2837
tapply(df.cat.entristirPAPN$Rating,df.cat.entristirPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 6.48, PN: 5.80 


#All verbs PI & PN
wilcox.test(df.cat.entristirPIPN$Rating ~ df.cat.entristirPIPN$Sentencetype) # = 0.0525
tapply(df.cat.entristirPIPN$Rating,df.cat.entristirPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 6.68, PN: 5.80 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            AA&PA, AI&PI
  - The variance does NOT differ significantly in the following pairs:    AA&AI, PA&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               PA&PN, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, PA&PI, PA&PN, PI&PN
  - The means do NOT differ significantly in the following pairs:         AA&PA, AI&PI



ESTRANYAR
```{r}

#Create relevant subsets to test for animacy effects throughout ESTRANYAR (U)
df.cat.estranyarAA <- subset(df.cat.allAA, Verb == "U")
df.cat.estranyarAI <- subset(df.cat.allAI, Verb == "U")
df.cat.estranyarPA <- subset(df.cat.allPA, Verb == "U")
df.cat.estranyarPI <- subset(df.cat.allPI, Verb == "U")
df.cat.estranyarPN <- subset(df.cat.allPN, Verb == "U")

```

```{r}
#Shapiro test to test for normal distribution among the ESTRANYAR (U) subsets
shapiro.test(df.cat.estranyarAA$Rating) # = 0.005381
shapiro.test(df.cat.estranyarAI$Rating) # = 0.004343
shapiro.test(df.cat.estranyarPA$Rating) # = 0.01279
shapiro.test(df.cat.estranyarPI$Rating) # = 2.635e-06
shapiro.test(df.cat.estranyarPN$Rating) # = 5.356e-07

```

```{r}

#Levene test

#new subsets that are fit for the levene test, i.e. the subgroups we want to compare 
#AA&AI vs. PA&PI, AA&PA vs. AI&PI, PN? (vs. PA or PI)
#Am preparing everything to compare PA&PN to PI&PN
#We can decide later whether and what is interesting (if anything)

df.cat.estranyarAAAI <- subset(df.cat, Verb=='U' & Sentencetype %in% c('AA','AI'))
df.cat.estranyarPAPI <- subset(df.cat, Verb=='U' & Sentencetype %in% c('PA','PI'))
df.cat.estranyarAAPA <- subset(df.cat, Verb=='U' & Sentencetype %in% c('AA','PA'))
df.cat.estranyarAIPI <- subset(df.cat, Verb=='U' & Sentencetype %in% c('AI','PI'))
df.cat.estranyarPAPN <- subset(df.cat, Verb=='U' & Sentencetype %in% c('PA','PN'))
df.cat.estranyarPIPN <- subset(df.cat, Verb=='U' & Sentencetype %in% c('PI','PN'))


#shapiro tests for new subsets
shapiro.test(df.cat.estranyarAAAI$Rating) # = 0.0002391
shapiro.test(df.cat.estranyarPAPI$Rating) # = 1.771e-06
shapiro.test(df.cat.estranyarAAPA$Rating) # = 0.000155
shapiro.test(df.cat.estranyarAIPI$Rating) # = 1.146e-05
shapiro.test(df.cat.estranyarPAPN$Rating) # = 3.071e-07
shapiro.test(df.cat.estranyarPIPN$Rating) # = 3.853e-10


#Levene Test to test for variance among all verbs
#ESTRANYAR verbs AA & AI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI) # 0.06178 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAAI, center=mean) # 0.01667 *


#ESTRANYAR verbs PA & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI) # 0.06473 .
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPI, center=mean) # 0.03259 *


#ESTRANYAR verbs AA & PA
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA) # 0.8166
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAAPA, center=mean) # 0.6733


#ESTRANYAR verbs AI & PI
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI) # 0.7695
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarAIPI, center=mean) # 0.8612


#ESTRANYAR verbs PA & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN) # 1.586e-05 ***
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPAPN, center=mean) # 9.595e-07 ***


#ESTRANYAR verbs PI & PN
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN) # 0.1093
leveneTest(Rating ~ Sentencetype, data = df.cat.estranyarPIPN, center=mean) # 0.02935 *

```

```{r}
#Mann-Whitney U test via wilcox function
#Comapres means; if p-value < 0.05 there's a significant difference between the two groups
#tapply function prints means
#na.rm = TRUE to exclude NA ratings

#ESTARNYAR AA & AI
wilcox.test(df.cat.estranyarAAAI$Rating ~ df.cat.estranyarAAAI$Sentencetype) # = 0.01087
tapply(df.cat.estranyarAAAI$Rating,df.cat.estranyarAAAI$Sentencetype,mean,na.rm = TRUE) # AA: 4.480000, AI: 2.833333 


#ESTRANYAR PA &PI
wilcox.test(df.cat.estranyarPAPI$Rating ~ df.cat.estranyarPAPI$Sentencetype) # = 0.002426
tapply(df.cat.estranyarPAPI$Rating,df.cat.estranyarPAPI$Sentencetype,mean,na.rm = TRUE) # PA: 4.40, PI: 5.96 


#ESTRANYAR AA & PA
wilcox.test(df.cat.estranyarAAPA$Rating ~ df.cat.estranyarAAPA$Sentencetype) # = 0.8287
tapply(df.cat.estranyarAAPA$Rating,df.cat.estranyarAAPA$Sentencetype,mean,na.rm = TRUE) # AA: 4.48, PA: 4.40 


#ESTRANYAR AI & PI
wilcox.test(df.cat.estranyarAIPI$Rating ~ df.cat.estranyarAIPI$Sentencetype) # = 1.42e-06
tapply(df.cat.estranyarAIPI$Rating,df.cat.estranyarAIPI$Sentencetype,mean,na.rm = TRUE) # AI: 2.833333, PI: 5.960000 


#ESTRANYAR PA & PN
wilcox.test(df.cat.estranyarPAPN$Rating ~ df.cat.estranyarPAPN$Sentencetype) # = 2.264e-05
tapply(df.cat.estranyarPAPN$Rating,df.cat.estranyarPAPN$Sentencetype,mean,na.rm = TRUE) # PA: 4.40, PN: 6.56 


#ESTRANYAR PI & PN
wilcox.test(df.cat.estranyarPIPN$Rating ~ df.cat.estranyarPIPN$Sentencetype) # = 0.2034
tapply(df.cat.estranyarPIPN$Rating,df.cat.estranyarPIPN$Sentencetype,mean,na.rm = TRUE) # PI: 5.96, PN: 6.56 

```

Comments:
  - None of the subsets are normally distributed.
  - The variance differs significantly in the following pairs:            PA&PN
  - The variance does NOT differ significantly in the following pairs:    AA&PA, AI&PI
  - The variance is uncertain in the following pairs due to stark
    differences in center = median vs mean:                               AA&AI, PA&PI, PI&PN
  - The means differ significantly in the following pairs:                AA&AI, PA&PI, AI&PI, PA&PN
  - The means do NOT differ significantly in the following pairs:         AA&PA, PI&PN